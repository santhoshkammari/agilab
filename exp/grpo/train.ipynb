{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547af385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"UNSLOTH_VLLM_STANDBY\"] = \"1\"# [NEW] Extra 30% context lengths!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c241f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ng6309/datascience/anand/vllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 10-08 00:15:45 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1008 00:15:45.401000 369457 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "W1008 00:15:45.401000 369457 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "Switching to PyTorch attention since your Xformers is broken.\n",
      "========\n",
      "\n",
      "Requires Flash-Attention version >=2.7.1,<=2.8.2 but got 2.8.3.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.9.9: Fast Lfm2 patching. Transformers: 4.56.2. vLLM: 0.10.2.\n",
      "   \\\\   /|    NVIDIA RTX 6000 Ada Generation. Num GPUs = 1. Max memory: 47.507 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n",
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 8000 # Can increase for longer reasoning traces\n",
    "lora_rank = 32 # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"LiquidAI/LFM2-350M\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False, # False for LoRA 16bit\n",
    "    fast_inference = False, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.9, # Reduce if out of memory\n",
    "\n",
    "    use_exact_model_name = True #for hugginface cache or repo mdoel name\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank*2, # *2 speeds up training\n",
    "    use_gradient_checkpointing = \"unsloth\", # Reduces memory usage\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22aabd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{{- bos_token -}}\\n{%- set system_prompt = \"\" -%}\\n{%- set ns = namespace(system_prompt=\"\") -%}\\n{%- if messages[0][\"role\"] == \"system\" -%}\\n\\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\\n\\t{%- set messages = messages[1:] -%}\\n{%- endif -%}\\n{%- if tools -%}\\n\\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"List of tools: <|tool_list_start|>[\" -%}\\n\\t{%- for tool in tools -%}\\n\\t\\t{%- if tool is not string -%}\\n            {%- set tool = tool | tojson -%}\\n\\t\\t{%- endif -%}\\n\\t\\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\\n        {%- if not loop.last -%}\\n            {%- set ns.system_prompt = ns.system_prompt + \", \" -%}\\n        {%- endif -%}\\n\\t{%- endfor -%}\\n\\t{%- set ns.system_prompt = ns.system_prompt + \"]<|tool_list_end|>\" -%}\\n{%- endif -%}\\n{%- if ns.system_prompt -%}\\n\\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\\n{%- endif -%}\\n{%- for message in messages -%}\\n\\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\\n\\t{%- set content = message[\"content\"] -%}\\n\\t{%- if content is not string -%}\\n\\t\\t{%- set content = content | tojson -%}\\n\\t{%- endif -%}\\n\\t{%- if message[\"role\"] == \"tool\" -%}\\n\\t\\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\\n\\t{%- endif -%}\\n\\t{{- content + \"<|im_end|>\\\\n\" -}}\\n{%- endfor -%}\\n{%- if add_generation_prompt -%}\\n\\t{{- \"<|im_start|>assistant\\\\n\" -}}\\n{%- endif -%}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f58ada15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean GLM-style template with line-by-line tool format\n",
    "glm_chat_template = '''{{- bos_token -}}\n",
    "{%- set system_prompt = \"\" -%}\n",
    "{%- set ns = namespace(system_prompt=\"\") -%}\n",
    "{%- if messages[0][\"role\"] == \"system\" -%}\n",
    "\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\n",
    "\t{%- set messages = messages[1:] -%}\n",
    "{%- endif -%}\n",
    "{%- if tools -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\\\\n\" -%}\n",
    "\t{%- for tool in tools -%}\n",
    "\t\t{%- if tool is not string -%}\n",
    "\t\t\t{%- set tool = tool.function | tojson -%}\n",
    "\t\t{%- endif -%}\n",
    "\t\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\n",
    "\t\t{%- if not loop.last -%}\n",
    "\t\t\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n\" -%}\n",
    "\t\t{%- endif -%}\n",
    "\t{%- endfor -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\n",
    "{%- endif -%}\n",
    "{%- if ns.system_prompt -%}\n",
    "\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endif -%}\n",
    "{%- for message in messages -%}\n",
    "\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\n",
    "\t{%- set content = message[\"content\"] -%}\n",
    "\t{%- if content is not string -%}\n",
    "\t\t{%- set content = content | tojson -%}\n",
    "\t{%- endif -%}\n",
    "\t{%- if message[\"role\"] == \"tool\" -%}\n",
    "\t\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\n",
    "\t{%- endif -%}\n",
    "\t{{- content + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endfor -%}\n",
    "{%- if add_generation_prompt -%}\n",
    "\t{{- \"<|im_start|>assistant\\\\n\" -}}\n",
    "{%- endif -%}'''\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e0e8b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you also search for all candidates for the position of Data Scientist?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>search_database\n",
      "<arg_key>query</arg_key>\n",
      "<arg_value>Data Scientist</arg_value>\n",
      "<arg_key>limit</arg_key>\n",
      "<arg_value>10</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "I found 2 candidates for the Data Scientist position:\n",
      "1. John Doe (ID: 67890) - Status: Applied\n",
      "2. Jane Smith (ID: 67891) - Status: Interview Completed<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you also search for all candidates for the position of Data Scientist?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>search_database\\n<arg_key>query</arg_key>\\n<arg_value>Data Scientist</arg_value>\\n<arg_key>limit</arg_key>\\n<arg_value>10</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]'},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found 2 candidates for the Data Scientist position:\\n1. John Doe (ID: 67890) - Status: Applied\\n2. Jane Smith (ID: 67891) - Status: Interview Completed\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71b61407",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tools = {\n",
    "  \"web_search\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"web_search\",\n",
    "      \"description\": \"Search the web\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Search query\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"query\"\n",
    "        ]\n",
    "      },\n",
    "      \"return\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "          \"type\": \"object\"\n",
    "        },\n",
    "        \"description\": \"The list of items having url,title,description.\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"think\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"think\",\n",
    "      \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"thought\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A thought to think about.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"thought\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"response\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"response\",\n",
    "      \"description\": \"Send a message back to the user.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"message\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The message to send to the user.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"message\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "142411a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "{\"name\": \"response\", \"description\": \"Send a message back to the user.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\", \"description\": \"The message to send to the user.\"}}, \"required\": [\"message\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "hiiii<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hiiii\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=list(base_tools.values()), \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa9441a",
   "metadata": {},
   "source": [
    "## Chattemplate Explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d19936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ '<|system|>\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"get_weather\", \"description\": \"Get the weather of a city for a specific date.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"city\": {\"type\": \"string\", \"description\": \"The city to get weather for, in Chinese.\"}, \"date\": {\"type\": \"string\", \"description\": \"The date in YYYY-MM-DD format.\"}}, \"required\": [\"city\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|system|>\n",
      "You are a helpful assistant.' + eos_token }\n",
      "{ '<|user|>' + message['content'] }\n",
      "{ '<|assistant|>' }\n"
     ]
    }
   ],
   "source": [
    "def create_glm_tool_template():\n",
    "    # GLM-4.6 style components\n",
    "    components = {\n",
    "        'think_start': '<think>',\n",
    "        'think_end': '</think>',\n",
    "        'tool_start': '<tool_call>',\n",
    "        'tool_end': '</tool_call>',\n",
    "        'arg_key_start': '<arg_key>',\n",
    "        'arg_key_end': '</arg_key>',\n",
    "        'arg_value_start': '<arg_value>',\n",
    "        'arg_value_end': '</arg_value>',\n",
    "        'observation_start': '<|observation|>',\n",
    "        'system_start': '<|system|>',\n",
    "        'user_start': '<|user|>',\n",
    "        'assistant_start': '<|assistant|>',\n",
    "        'solution_start': '<SOLUTION>',\n",
    "        'solution_end': '</SOLUTION>'\n",
    "    }\n",
    "    \n",
    "    system_prompt_with_tools = f\"\"\"{components['system_start']}\n",
    "# Tools\n",
    "You may call one or more functions to assist with the user query.\n",
    "You are provided with function signatures within <tools></tools> XML tags:\n",
    "<tools>\n",
    "{{\"name\": \"get_weather\", \"description\": \"Get the weather of a city for a specific date.\", \"parameters\": {{\"type\": \"object\", \"properties\": {{\"city\": {{\"type\": \"string\", \"description\": \"The city to get weather for, in Chinese.\"}}, \"date\": {{\"type\": \"string\", \"description\": \"The date in YYYY-MM-DD format.\"}}}}, \"required\": [\"city\"]}}}}\n",
    "</tools>\n",
    "For each function call, output the function name and arguments within the following XML format:\n",
    "{components['tool_start']}{{function-name}}\n",
    "{components['arg_key_start']}{{arg_key}}{components['arg_key_end']}\n",
    "{components['arg_value_start']}{{arg_value}}{components['arg_value_end']}\n",
    "...\n",
    "{components['tool_end']}{components['system_start']}\n",
    "You are a helpful assistant.\"\"\"\n",
    "    \n",
    "    chat_template = f\"\"\"{{% if messages[0]['role'] == 'system' %}}\n",
    "{{ messages[0]['content'] + eos_token }}\n",
    "{{% set loop_messages = messages[1:] %}}\n",
    "{{% else %}}\n",
    "{{ '{system_prompt_with_tools}' + eos_token }}\n",
    "{{% set loop_messages = messages %}}\n",
    "{{% endif %}}\n",
    "{{% for message in loop_messages %}}\n",
    "{{% if message['role'] == 'user' %}}\n",
    "{{ '<|user|>' + message['content'] }}\n",
    "{{% elif message['role'] == 'assistant' %}}\n",
    "{{ '<|assistant|>' + message['content'] + eos_token }}\n",
    "{{% elif message['role'] == 'observation' %}}\n",
    "{{ '<|observation|>' + message['content'] + '<|assistant|>' }}\n",
    "{{% endif %}}\n",
    "{{% endfor %}}\n",
    "{{% if add_generation_prompt %}}{{ '<|assistant|>' }}{{% endif %}}\"\"\"\n",
    "    \n",
    "    return chat_template\n",
    "\n",
    "# Apply the template\n",
    "tokenizer.chat_template = create_glm_tool_template()\n",
    "\n",
    "# Example usage:\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Today is June 26, 2024. Could you please check the weather in Beijing and Shanghai for tomorrow?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"<think>The user wants to check the weather of Beijing and Shanghai tomorrow. I need to call the get_weather function respectively to check Beijing and Shanghai.</think>\\nI will call the get_weather function to check the weather in Beijing and Shanghai.\\n<tool_call>get_weather\\n<arg_key>city</arg_key>\\n<arg_value>Beijing</arg_value>\\n<arg_key>date</arg_key>\\n<arg_value>2024-06-27</arg_value>\\n</tool_call>\\n<tool_call>get_weather\\n<arg_key>city</arg_key>\\n<arg_value>Shanghai</arg_value>\\n<arg_key>date</arg_key>\\n<arg_value>2024-06-27</arg_value>\\n</tool_call>\"},\n",
    "    {\"role\": \"observation\", \"content\": '[{\"city\": \"Beijing\", \"date\": \"2024-06-27\", \"weather\": \"Sunny\", \"temperature\": \"26C\"}, {\"city\": \"Shanghai\", \"date\": \"2024-06-27\", \"weather\": \"Overcast\", \"temperature\": \"29C\"}]'},\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hi\"},\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85758d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "List of tools: <|tool_list_start|>[{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}]<|tool_list_end|><|im_end|>\n",
      "<|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "def create_advanced_glm_compatible_template():\n",
    "    chat_template = \"\"\"{% if messages[0]['role'] == 'system' %}\n",
    "{{ '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>' }}\n",
    "{% set loop_messages = messages[1:] %}\n",
    "{% else %}\n",
    "{{ '<|im_start|>system\\nList of tools: <|tool_list_start|>[{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}]<|tool_list_end|><|im_end|>' }}\n",
    "{% set loop_messages = messages %}\n",
    "{% endif %}\n",
    "{% for message in loop_messages %}\n",
    "{% if message['role'] == 'user' %}\n",
    "{{ '<|im_start|>user\\n' + message['content'] + '<|im_end|>' }}\n",
    "{% elif message['role'] == 'assistant' %}\n",
    "{{ '<|im_start|>assistant\\n' + message['content'] + '<|im_end|>' }}\n",
    "{% elif message['role'] == 'tool' or message['role'] == 'observation' %}\n",
    "{{ '<|im_start|>tool\\n<|tool_response_start|>' + message['content'] + '<|tool_response_end|><|im_end|>' }}\n",
    "{% endif %}\n",
    "{% endfor %}\n",
    "{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n<think>' }}{% endif %}\"\"\"\n",
    "    \n",
    "    return chat_template\n",
    "\n",
    "tokenizer.chat_template = create_advanced_glm_compatible_template()\n",
    "\n",
    "# Example with GLM-style tool calls:\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\\n<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f6523f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "null\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|system|>\n",
      "You are a helpful assistant.<|im_end|><|user|>hi<|assistant|>\n",
      "\n",
      "==================================================\n",
      "\n",
      "<|system|>\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "null\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|system|>\n",
      "You are a helpful assistant.<|im_end|><|user|>What is the current status of candidate ID 12345?<|assistant|><think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|><|observation|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|assistant|><|assistant|>The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|><|assistant|>\n"
     ]
    }
   ],
   "source": [
    "def create_glm_tool_template(tools_list=None):\n",
    "    import json\n",
    "    tools_json = json.dumps(tools_list, ensure_ascii=False)\n",
    "    \n",
    "    system_prompt_with_tools = f\"\"\"<|system|>\n",
    "# Tools\n",
    "You may call one or more functions to assist with the user query.\n",
    "You are provided with function signatures within <tools></tools> XML tags:\n",
    "<tools>\n",
    "{tools_json}\n",
    "</tools>\n",
    "For each function call, output the function name and arguments within the following XML format:\n",
    "<tool_call>{{function-name}}\n",
    "<arg_key>{{arg_key}}</arg_key>\n",
    "<arg_value>{{arg_value}}</arg_value>\n",
    "...\n",
    "</tool_call><|system|>\n",
    "You are a helpful assistant.\"\"\"\n",
    "    \n",
    "    chat_template = (\n",
    "        \"{% if messages[0]['role'] == 'system' %}\"\n",
    "        \"{{ messages[0]['content'] + eos_token }}\"\n",
    "        \"{% set loop_messages = messages[1:] %}\"\n",
    "        \"{% else %}\"\n",
    "        \"{{ '\" + system_prompt_with_tools.replace('\\n', '\\\\n').replace('\"', '\\\\\"') + \"' + eos_token }}\"\n",
    "        \"{% set loop_messages = messages %}\"\n",
    "        \"{% endif %}\"\n",
    "        \"{% for message in loop_messages %}\"\n",
    "        \"{% if message['role'] == 'user' %}\"\n",
    "        \"{{ '<|user|>' + message['content'] }}\"\n",
    "        \"{% elif message['role'] == 'assistant' %}\"\n",
    "        \"{{ '<|assistant|>' + message['content'] + eos_token }}\"\n",
    "        \"{% elif message['role'] == 'observation' %}\"\n",
    "        \"{{ '<|observation|>' + message['content'] + '<|assistant|>' }}\"\n",
    "        \"{% endif %}\"\n",
    "        \"{% endfor %}\"\n",
    "        \"{% if add_generation_prompt %}{{ '<|assistant|>' }}{% endif %}\"\n",
    "    )\n",
    "    \n",
    "    return chat_template\n",
    "\n",
    "# Example with custom tools\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"search_database\",\n",
    "        \"description\": \"Search the database for specific information\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"The search query\"},\n",
    "                \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create template with custom tools\n",
    "tokenizer.chat_template = create_glm_tool_template()\n",
    "\n",
    "# Test\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hi\"},\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools,\n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test with a full conversation\n",
    "messages_with_tools = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\\n<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"observation\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"}\n",
    "]\n",
    "\n",
    "formatted_full = tokenizer.apply_chat_template(\n",
    "    messages_with_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d93b20b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>[{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}]</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "hi<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "# GLM-style template that preserves the tools parameter functionality\n",
    "glm_chat_template = (\n",
    "    '{{- bos_token -}}\\n'\n",
    "    '{%- set system_prompt = \"\" -%}\\n'\n",
    "    '{%- set ns = namespace(system_prompt=\"\") -%}\\n'\n",
    "    '{%- if messages[0][\"role\"] == \"system\" -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\\n'\n",
    "    '\\t{%- set messages = messages[1:] -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if tools -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>[\" -%}\\n'\n",
    "    '\\t{%- for tool in tools -%}\\n'\n",
    "    '\\t\\t{%- if tool is not string -%}\\n'\n",
    "    '\\t\\t\\t{%- set tool = tool | tojson -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t\\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\\n'\n",
    "    '\\t\\t{%- if not loop.last -%}\\n'\n",
    "    '\\t\\t\\t{%- set ns.system_prompt = ns.system_prompt + \", \" -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t{%- endfor -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + \"]</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if ns.system_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- for message in messages -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\\n'\n",
    "    '\\t{%- set content = message[\"content\"] -%}\\n'\n",
    "    '\\t{%- if content is not string -%}\\n'\n",
    "    '\\t\\t{%- set content = content | tojson -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{%- if message[\"role\"] == \"tool\" -%}\\n'\n",
    "    '\\t\\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{{- content + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endfor -%}\\n'\n",
    "    '{%- if add_generation_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>assistant\\\\n<think>\" -}}\\n'\n",
    "    '{%- endif -%}'\n",
    ")\n",
    "\n",
    "# Apply the new template\n",
    "tokenizer.chat_template = glm_chat_template\n",
    "\n",
    "# Test it\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hi\"},\n",
    "]\n",
    "\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# This should now work with tools parameter\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3aefffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>[{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}, {\"name\": \"search_database\", \"description\": \"Search the database for specific information\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"The search query\"}, \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}}, \"required\": [\"query\"]}}]</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you also search for all candidates for the position of Data Scientist?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>The user wants to search for all candidates for the Data Scientist position. I need to use the search_database tool.</think>\n",
      "<tool_call>search_database\n",
      "<arg_key>query</arg_key>\n",
      "<arg_value>Data Scientist</arg_value>\n",
      "<arg_key>limit</arg_key>\n",
      "<arg_value>10</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "I found 2 candidates for the Data Scientist position:\n",
      "1. John Doe (ID: 67890) - Status: Applied\n",
      "2. Jane Smith (ID: 67891) - Status: Interview Completed<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make sure we have the GLM template applied\n",
    "glm_chat_template = (\n",
    "    '{{- bos_token -}}\\n'\n",
    "    '{%- set system_prompt = \"\" -%}\\n'\n",
    "    '{%- set ns = namespace(system_prompt=\"\") -%}\\n'\n",
    "    '{%- if messages[0][\"role\"] == \"system\" -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\\n'\n",
    "    '\\t{%- set messages = messages[1:] -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if tools -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>[\" -%}\\n'\n",
    "    '\\t{%- for tool in tools -%}\\n'\n",
    "    '\\t\\t{%- if tool is not string -%}\\n'\n",
    "    '\\t\\t\\t{%- set tool = tool | tojson -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t\\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\\n'\n",
    "    '\\t\\t{%- if not loop.last -%}\\n'\n",
    "    '\\t\\t\\t{%- set ns.system_prompt = ns.system_prompt + \", \" -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t{%- endfor -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + \"]</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if ns.system_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- for message in messages -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\\n'\n",
    "    '\\t{%- set content = message[\"content\"] -%}\\n'\n",
    "    '\\t{%- if content is not string -%}\\n'\n",
    "    '\\t\\t{%- set content = content | tojson -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{%- if message[\"role\"] == \"tool\" -%}\\n'\n",
    "    '\\t\\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{{- content + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endfor -%}\\n'\n",
    "    '{%- if add_generation_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>assistant\\\\n<think>\" -}}\\n'\n",
    "    '{%- endif -%}'\n",
    ")\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template\n",
    "\n",
    "# Example with complete conversation flow\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"search_database\",\n",
    "        \"description\": \"Search the database for specific information\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"The search query\"},\n",
    "                \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Complete conversation with user, assistant, and tool messages\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\\n<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you also search for all candidates for the position of Data Scientist?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<think>The user wants to search for all candidates for the Data Scientist position. I need to use the search_database tool.</think>\\n<tool_call>search_database\\n<arg_key>query</arg_key>\\n<arg_value>Data Scientist</arg_value>\\n<arg_key>limit</arg_key>\\n<arg_value>10</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]'},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found 2 candidates for the Data Scientist position:\\n1. John Doe (ID: 67890) - Status: Applied\\n2. Jane Smith (ID: 67891) - Status: Interview Completed\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False  # Don't add generation prompt for complete conversation\n",
    ")\n",
    "\n",
    "print(formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e472f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>[{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}, {\"name\": \"search_database\", \"description\": \"Search the database for specific information\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"The search query\"}, \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}}, \"required\": [\"query\"]}}]</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you also search for all candidates for the position of Data Scientist?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>search_database\n",
      "<arg_key>query</arg_key>\n",
      "<arg_value>Data Scientist</arg_value>\n",
      "<arg_key>limit</arg_key>\n",
      "<arg_value>10</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "I found 2 candidates for the Data Scientist position:\n",
      "1. John Doe (ID: 67890) - Status: Applied\n",
      "2. Jane Smith (ID: 67891) - Status: Interview Completed<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GLM-style template without think tags\n",
    "glm_chat_template = (\n",
    "    '{{- bos_token -}}\\n'\n",
    "    '{%- set system_prompt = \"\" -%}\\n'\n",
    "    '{%- set ns = namespace(system_prompt=\"\") -%}\\n'\n",
    "    '{%- if messages[0][\"role\"] == \"system\" -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\\n'\n",
    "    '\\t{%- set messages = messages[1:] -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if tools -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>[\" -%}\\n'\n",
    "    '\\t{%- for tool in tools -%}\\n'\n",
    "    '\\t\\t{%- if tool is not string -%}\\n'\n",
    "    '\\t\\t\\t{%- set tool = tool | tojson -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t\\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\\n'\n",
    "    '\\t\\t{%- if not loop.last -%}\\n'\n",
    "    '\\t\\t\\t{%- set ns.system_prompt = ns.system_prompt + \", \" -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t{%- endfor -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + \"]</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if ns.system_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- for message in messages -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\\n'\n",
    "    '\\t{%- set content = message[\"content\"] -%}\\n'\n",
    "    '\\t{%- if content is not string -%}\\n'\n",
    "    '\\t\\t{%- set content = content | tojson -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{%- if message[\"role\"] == \"tool\" -%}\\n'\n",
    "    '\\t\\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{{- content + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endfor -%}\\n'\n",
    "    '{%- if add_generation_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>assistant\\\\n\" -}}\\n'\n",
    "    '{%- endif -%}'\n",
    ")\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template\n",
    "\n",
    "# Example with complete conversation flow (without think tags)\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"search_database\",\n",
    "        \"description\": \"Search the database for specific information\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"The search query\"},\n",
    "                \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you also search for all candidates for the position of Data Scientist?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>search_database\\n<arg_key>query</arg_key>\\n<arg_value>Data Scientist</arg_value>\\n<arg_key>limit</arg_key>\\n<arg_value>10</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]'},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found 2 candidates for the Data Scientist position:\\n1. John Doe (ID: 67890) - Status: Applied\\n2. Jane Smith (ID: 67891) - Status: Interview Completed\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f072aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "hi<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}\n",
      "{\"name\": \"search_database\", \"description\": \"Search the database for specific information\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"The search query\"}, \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}}, \"required\": [\"query\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you also search for all candidates for the position of Data Scientist?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>search_database\n",
      "<arg_key>query</arg_key>\n",
      "<arg_value>Data Scientist</arg_value>\n",
      "<arg_key>limit</arg_key>\n",
      "<arg_value>10</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "I found 2 candidates for the Data Scientist position:\n",
      "1. John Doe (ID: 67890) - Status: Applied\n",
      "2. Jane Smith (ID: 67891) - Status: Interview Completed<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean GLM-style template with line-by-line tool format\n",
    "glm_chat_template = '''{{- bos_token -}}\n",
    "{%- set system_prompt = \"\" -%}\n",
    "{%- set ns = namespace(system_prompt=\"\") -%}\n",
    "{%- if messages[0][\"role\"] == \"system\" -%}\n",
    "\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\n",
    "\t{%- set messages = messages[1:] -%}\n",
    "{%- endif -%}\n",
    "{%- if tools -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\\\\n\" -%}\n",
    "\t{%- for tool in tools -%}\n",
    "\t\t{%- if tool is not string -%}\n",
    "\t\t\t{%- set tool = tool | tojson -%}\n",
    "\t\t{%- endif -%}\n",
    "\t\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\n",
    "\t\t{%- if not loop.last -%}\n",
    "\t\t\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n\" -%}\n",
    "\t\t{%- endif -%}\n",
    "\t{%- endfor -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\n",
    "{%- endif -%}\n",
    "{%- if ns.system_prompt -%}\n",
    "\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endif -%}\n",
    "{%- for message in messages -%}\n",
    "\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\n",
    "\t{%- set content = message[\"content\"] -%}\n",
    "\t{%- if content is not string -%}\n",
    "\t\t{%- set content = content | tojson -%}\n",
    "\t{%- endif -%}\n",
    "\t{%- if message[\"role\"] == \"tool\" -%}\n",
    "\t\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\n",
    "\t{%- endif -%}\n",
    "\t{{- content + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endfor -%}\n",
    "{%- if add_generation_prompt -%}\n",
    "\t{{- \"<|im_start|>assistant\\\\n\" -}}\n",
    "{%- endif -%}'''\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template\n",
    "\n",
    "# Test with tools\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hi\"},\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted)\n",
    "\n",
    "\n",
    "\n",
    "# Example with complete conversation flow (without think tags)\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"search_database\",\n",
    "        \"description\": \"Search the database for specific information\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"The search query\"},\n",
    "                \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you also search for all candidates for the position of Data Scientist?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>search_database\\n<arg_key>query</arg_key>\\n<arg_value>Data Scientist</arg_value>\\n<arg_key>limit</arg_key>\\n<arg_value>10</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]'},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found 2 candidates for the Data Scientist position:\\n1. John Doe (ID: 67890) - Status: Applied\\n2. Jane Smith (ID: 67891) - Status: Interview Completed\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

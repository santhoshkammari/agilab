{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547af385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"UNSLOTH_VLLM_STANDBY\"] = \"1\"# [NEW] Extra 30% context lengths!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c241f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ng6309/datascience/anand/vllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 10-08 02:58:57 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1008 02:58:57.884000 592413 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "W1008 02:58:57.884000 592413 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "Switching to PyTorch attention since your Xformers is broken.\n",
      "========\n",
      "\n",
      "Requires Flash-Attention version >=2.7.1,<=2.8.2 but got 2.8.3.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.10.1: Fast Lfm2 patching. Transformers: 4.56.2. vLLM: 0.10.2.\n",
      "   \\\\   /|    NVIDIA RTX 6000 Ada Generation. Num GPUs = 1. Max memory: 47.507 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n",
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 8000 # Can increase for longer reasoning traces\n",
    "lora_rank = 32 # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"LiquidAI/LFM2-350M\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False, # False for LoRA 16bit\n",
    "    fast_inference = False, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.9, # Reduce if out of memory\n",
    "\n",
    "    use_exact_model_name = True #for hugginface cache or repo mdoel name\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank*2, # *2 speeds up training\n",
    "    use_gradient_checkpointing = \"unsloth\", # Reduces memory usage\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22aabd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{{- bos_token -}}\\n{%- set system_prompt = \"\" -%}\\n{%- set ns = namespace(system_prompt=\"\") -%}\\n{%- if messages[0][\"role\"] == \"system\" -%}\\n\\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\\n\\t{%- set messages = messages[1:] -%}\\n{%- endif -%}\\n{%- if tools -%}\\n\\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"List of tools: <|tool_list_start|>[\" -%}\\n\\t{%- for tool in tools -%}\\n\\t\\t{%- if tool is not string -%}\\n            {%- set tool = tool | tojson -%}\\n\\t\\t{%- endif -%}\\n\\t\\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\\n        {%- if not loop.last -%}\\n            {%- set ns.system_prompt = ns.system_prompt + \", \" -%}\\n        {%- endif -%}\\n\\t{%- endfor -%}\\n\\t{%- set ns.system_prompt = ns.system_prompt + \"]<|tool_list_end|>\" -%}\\n{%- endif -%}\\n{%- if ns.system_prompt -%}\\n\\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\\n{%- endif -%}\\n{%- for message in messages -%}\\n\\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\\n\\t{%- set content = message[\"content\"] -%}\\n\\t{%- if content is not string -%}\\n\\t\\t{%- set content = content | tojson -%}\\n\\t{%- endif -%}\\n\\t{%- if message[\"role\"] == \"tool\" -%}\\n\\t\\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\\n\\t{%- endif -%}\\n\\t{{- content + \"<|im_end|>\\\\n\" -}}\\n{%- endfor -%}\\n{%- if add_generation_prompt -%}\\n\\t{{- \"<|im_start|>assistant\\\\n\" -}}\\n{%- endif -%}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58ada15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean GLM-style template with line-by-line tool format\n",
    "glm_chat_template = '''{{- bos_token -}}\n",
    "{%- set system_prompt = \"\" -%}\n",
    "{%- set ns = namespace(system_prompt=\"\") -%}\n",
    "{%- if messages[0][\"role\"] == \"system\" -%}\n",
    "\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\n",
    "\t{%- set messages = messages[1:] -%}\n",
    "{%- endif -%}\n",
    "{%- if tools -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\\\\n\" -%}\n",
    "\t{%- for tool in tools -%}\n",
    "\t\t{%- if tool is not string -%}\n",
    "\t\t\t{%- set tool = tool.function | tojson -%}\n",
    "\t\t{%- endif -%}\n",
    "\t\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\n",
    "\t\t{%- if not loop.last -%}\n",
    "\t\t\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n\" -%}\n",
    "\t\t{%- endif -%}\n",
    "\t{%- endfor -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\n",
    "{%- endif -%}\n",
    "{%- if ns.system_prompt -%}\n",
    "\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endif -%}\n",
    "{%- for message in messages -%}\n",
    "\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\n",
    "\t{%- set content = message[\"content\"] -%}\n",
    "\t{%- if content is not string -%}\n",
    "\t\t{%- set content = content | tojson -%}\n",
    "\t{%- endif -%}\n",
    "\t{%- if message[\"role\"] == \"tool\" -%}\n",
    "\t\t{%- set content = \"\\n<|observation|>\\n<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\n",
    "\t{%- endif -%}\n",
    "\t{{- content + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endfor -%}\n",
    "{%- if add_generation_prompt -%}\n",
    "\t{{- \"<|im_start|>assistant\\\\n\" -}}\n",
    "{%- endif -%}'''\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b61407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  \"response\": {\\n    \"type\": \"function\",\\n    \"function\": {\\n      \"name\": \"response\",\\n      \"description\": \"Send a message back to the user.\",\\n      \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n          \"message\": {\\n            \"type\": \"string\",\\n            \"description\": \"The message to send to the user.\"\\n          }\\n        },\\n        \"required\": [\\n          \"message\"\\n        ]\\n      }\\n    }\\n  }\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tools = {\n",
    "  \"web_search\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"web_search\",\n",
    "      \"description\": \"Search the web\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Search query\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"query\"\n",
    "        ]\n",
    "      },\n",
    "      \"return\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "          \"type\": \"object\"\n",
    "        },\n",
    "        \"description\": \"The list of items having url,title,description.\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"think\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"think\",\n",
    "      \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"thought\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A thought to think about.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"thought\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "  \"response\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"response\",\n",
    "      \"description\": \"Send a message back to the user.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"message\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The message to send to the user.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"message\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142411a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "hiiii<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hiiii\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=list(base_tools.values()), \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d051d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "\n",
      "<|observation|>\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you also search for all candidates for the position of Data Scientist?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>search_database\n",
      "<arg_key>query</arg_key>\n",
      "<arg_value>Data Scientist</arg_value>\n",
      "<arg_key>limit</arg_key>\n",
      "<arg_value>10</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "\n",
      "<|observation|>\n",
      "<|tool_response_start|>[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "I found 2 candidates for the Data Scientist position:\n",
      "1. John Doe (ID: 67890) - Status: Applied\n",
      "2. Jane Smith (ID: 67891) - Status: Interview Completed<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you also search for all candidates for the position of Data Scientist?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>search_database\\n<arg_key>query</arg_key>\\n<arg_value>Data Scientist</arg_value>\\n<arg_key>limit</arg_key>\\n<arg_value>10</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]'},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found 2 candidates for the Data Scientist position:\\n1. John Doe (ID: 67890) - Status: Applied\\n2. Jane Smith (ID: 67891) - Status: Interview Completed\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tools=list(base_tools.values()),\n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99305bb",
   "metadata": {},
   "source": [
    "## Pre fine-tuning for formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46229cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'conversations'],\n",
       "        num_rows: 11300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Team-ACE/ToolACE\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003f863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tool_call>Get Zip Code Information\n",
      "<arg_key>country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001\")</arg_value>\n",
      "<arg_key>Get Zip Code sdf(country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001</arg_value>\n",
      "</tool_call>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_assistant_response(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    # Match pattern: [FunctionName(arg1=\"val1\", arg2='val2', ...)]\n",
    "    match = re.match(r'\\[(\\w+(?:\\s+\\w+)*)\\((.*)\\)\\]', text)\n",
    "    if not match:\n",
    "        return text  # Not a tool call â†’ return as-is\n",
    "\n",
    "    func_name = match.group(1)\n",
    "    args_str = match.group(2)\n",
    "\n",
    "    # Parse key=value pairs (support both \"...\" and '...')\n",
    "    args = []\n",
    "    for pair in args_str.split(','):\n",
    "        pair = pair.strip()\n",
    "        if '=' in pair:\n",
    "            key, value = pair.split('=', 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip().strip('\"').strip(\"'\")\n",
    "            args.append((key, value))\n",
    "\n",
    "    # Build XML-style output\n",
    "    xml_lines = [f\"<tool_call>{func_name}\"]\n",
    "    for k, v in args:\n",
    "        xml_lines.append(f\"<arg_key>{k}</arg_key>\")\n",
    "        xml_lines.append(f\"<arg_value>{v}</arg_value>\")\n",
    "    xml_lines.append(\"</tool_call>\")\n",
    "    \n",
    "    return \"\\n\".join(xml_lines)\n",
    "\n",
    "inp = '[Get Zip Code Information(country=\"us\", postal_code=\"10001\"),Get Zip Code sdf(country=\"us\", postal_code=\"10001\")]'\n",
    "print(convert_assistant_response(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9bd746d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'conversations', 'messages', 'tools'],\n",
       "        num_rows: 11300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_to_messages(example):\n",
    "    _messages = []\n",
    "    tools = example['system'].split(\"Here is a list of functions in JSON format that you can invoke:\")[-1].strip().split(\"Should you decide to return the function call(s)\")[0].replace(\". \\n\",\"\")\n",
    "    for x in example['conversations']:\n",
    "        if x['from'] ==\"assistant\":\n",
    "            _messages.append({\"role\":x['from'],\"content\":convert_assistant_response(x['value'])})\n",
    "        else:\n",
    "            _messages.append({\"role\":x['from'],\"content\":x['value']})\n",
    "\n",
    "    return {\"messages\":_messages,\"tools\":tools}\n",
    "\n",
    "dataset = dataset.map(convert_to_messages,num_proc=32)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b0106b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'conversations', 'messages', 'tools'],\n",
       "        num_rows: 10782\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_tool(example):\n",
    "    try:\n",
    "            json.loads(example['tools'])\n",
    "    except Exception as e:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "dataset = dataset.filter(filter_tool,num_proc=32)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2789045d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'conversations', 'messages', 'tools', 'prompt'],\n",
       "        num_rows: 10782\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def normalize_tool(tool):\n",
    "    # If already in correct format, return as-is\n",
    "    if \"type\" in tool and tool.get(\"type\") == \"function\" and \"function\" in tool:\n",
    "        return tool\n",
    "\n",
    "    # Otherwise, assume it's the old flat format\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": tool[\"name\"],\n",
    "            \"description\": tool.get(\"description\", \"\"),\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": tool.get(\"parameters\", {}).get(\"properties\", {}),\n",
    "                \"required\": tool.get(\"parameters\", {}).get(\"required\", [])\n",
    "                # Note: ignore top-level \"required\": null\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def apply_chat_template(example):\n",
    "    dynamic_tools = json.loads(example['tools'])\n",
    "    normalized_dynamic_tools = [normalize_tool(t) for t in dynamic_tools]\n",
    "    all_tools = list(base_tools.values()) + normalized_dynamic_tools\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        example['messages'],\n",
    "        tools=all_tools,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    return {\"prompt\": prompt}\n",
    "\n",
    "dataset = dataset.map(apply_chat_template,num_proc=32)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6082cc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "{\"name\": \"Quotes by Keywords\", \"description\": \"Returns a list of quotes containing the specified keyword.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"word\": {\"description\": \"The keyword to search for in quotes.\", \"type\": \"string\"}}, \"required\": [\"word\"]}}\n",
      "{\"name\": \"Get Zip Code Information\", \"description\": \"Retrieve information about a specific zip code in the United States.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"country\": {\"description\": \"The country code (default: 'us')\", \"type\": \"string\"}, \"postal_code\": {\"description\": \"The zip code (default: '90210')\", \"type\": \"string\"}}, \"required\": [\"country\", \"postal_code\"]}}\n",
      "{\"name\": \"Weekly Hot 100 Chart\", \"description\": \"Retrieve the Billboard Hot 100 chart for a specific string.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"string\": {\"description\": \"The string for which to retrieve the chart (YYYY-MM-DD)\", \"type\": \"string\"}}, \"required\": [\"string\"]}}\n",
      "{\"name\": \"Get Cars Information\", \"description\": \"This API returns a list of cars information based on the provided parameters.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"model\": {\"description\": \"The model of the vehicle.\", \"type\": \"string\"}, \"make\": {\"description\": \"The manufacturer of the vehicle.\", \"type\": \"string\"}, \"year\": {\"description\": \"The model year of the vehicle.\", \"type\": \"string\"}, \"fuel_type\": {\"description\": \"The type of fuel used.\", \"type\": \"string\"}, \"drive\": {\"description\": \"The drive transmission type.\", \"type\": \"string\"}, \"transmission\": {\"description\": \"The type of transmission.\", \"type\": \"string\"}, \"cylinders\": {\"description\": \"The number of cylinders.\", \"type\": \"float\"}, \"min_city_mpg\": {\"description\": \"Minimum city fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"max_city_mpg\": {\"description\": \"Maximum city fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"min_hwy_mpg\": {\"description\": \"Minimum highway fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"max_hwy_mpg\": {\"description\": \"Maximum highway fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"min_comb_mpg\": {\"description\": \"Minimum combination (city + highway) fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"max_comb_mpg\": {\"description\": \"Maximum combination (city + highway) fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"limit\": {\"description\": \"How many results to return.\", \"type\": \"string\"}}, \"required\": []}}\n",
      "{\"name\": \"Lorem Ipsum Generator\", \"description\": \"Generate a specified number of words of Lorem Ipsum text\", \"parameters\": {\"type\": \"object\", \"properties\": {\"amount\": {\"description\": \"The number of words to generate\", \"type\": \"int\"}}, \"required\": [\"amount\"]}}\n",
      "{\"name\": \"Crawl\", \"description\": \"Perform a Google search and return the HTML source of the results page.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"description\": \"The search query to perform.\", \"type\": \"string\"}}, \"required\": [\"query\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "Could you please find me some quotes about \"inspiration\"?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>Quotes by Keywords\n",
      "<arg_key>word</arg_key>\n",
      "<arg_value>inspiration</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "\n",
      "<|observation|>\n",
      "<|tool_response_start|>[{\"name\": \"Quotes by Keywords\", \"results\": {\"quotes\": [{\"text\": \"The only way to achieve the impossible is to believe it is possible.\", \"author\": \"Charles Kingsleigh\"}, {\"text\": \"Don't watch the clock; do what it does. Keep going.\", \"author\": \"Sam Levenson\"}, {\"text\": \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful.\", \"author\": \"Albert Schweitzer\"}]}}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "Here are some inspiration quotes for you:\n",
      "\n",
      "1. \"The only way to achieve the impossible is to believe it is possible.\" - Charles Kingsleigh\n",
      "2. \"Don't watch the clock; do what it does. Keep going.\" - Sam Levenson\n",
      "3. \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful.\" - Albert Schweitzer\n",
      "\n",
      "Feel free to reflect on these or let me know if you need more quotes or information on another topic!<|im_end|>\n",
      "<|im_start|>user\n",
      "Could you summarize the meaning of the quote by Albert Schweitzer?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The quote by Albert Schweitzer, \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful,\" emphasizes that true success in life comes from finding joy and fulfillment in what you do. Rather than viewing success as a source of happiness, Schweitzer suggests that happiness itself should be the foundation for achieving success. Essentially, when you engage in activities that make you happy and passionate, you're more likely to excel and achieve success in those ventures.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you dig up some juicy details about the zip code 10001? I'm doing a mail-order flamingo business plan, don't ask why.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>Get Zip Code Information\n",
      "<arg_key>country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "\n",
      "<|observation|>\n",
      "<|tool_response_start|>[{\"name\": \"Get Zip Code Information\", \"results\": {\"information\": \"Zip code information for 10001, USA\", \"latitude\": 40.748817, \"longitude\": -73.985428, \"city\": \"New York\", \"state\": \"NY\", \"county\": \"New York\"}}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "Here's the detailed information about the zip code 10001, which will be helpful for your mail-order flamingo business plan:\n",
      "\n",
      "**Zip Code Information for 10001, USA:**\n",
      "- **City:** New York\n",
      "- **State:** NY (New York)\n",
      "- **County:** New York\n",
      "- **Latitude:** 40.748817\n",
      "- **Longitude:** -73.985428\n",
      "\n",
      "This data provides a clear overview of where the zip code is located and its associated geographic details. If you need more assistance or information on any other aspect of your business plan, feel free to ask!<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][1]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca7c4a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"name\": \"newAddress\", \"description\": \"Generates a new Ethereum address that can be used to send or receive funds. Do not lose the password! We can\\'t restore access to an address if you lose it.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"password\": {\"description\": \"The password for the new Ethereum address\", \"type\": \"string\"}}, \"required\": [\"password\"]}, \"required\": null}, {\"name\": \"Market Trends API\", \"description\": \"Get the latest market trends and relevant news for a specified country and language.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"trend_type\": {\"description\": \"Trend type.\", \"type\": \"string\", \"enum\": [\"MARKET_INDEXES\", \"MOST_ACTIVE\", \"GAINERS\", \"LOSERS\", \"CRYPTO\", \"CURRENCIES\", \"CLIMATE_LEADERS\"]}, \"country\": {\"description\": \"The country for which to get trends, specified as a 2-letter country code - see ISO 3166.\", \"type\": \"string\", \"default\": \"us\"}, \"language\": {\"description\": \"The language to use for the results, specified as a 2-letter language code - see ISO 639-1.\", \"type\": \"string\", \"default\": \"en\"}}, \"required\": [\"trend_type\"]}, \"required\": null}, {\"name\": \"Get Futures Prices\", \"description\": \"Retrieve a list of current futures prices for various financial instruments.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"instrument_type\": {\"description\": \"Type of financial instrument (e.g., commodity, currency, index)\", \"type\": \"string\"}, \"exchange\": {\"description\": \"Name of the exchange (e.g., CME, ICE, NYMEX)\", \"type\": \"string\"}, \"start_string\": {\"description\": \"Start string for the price data (YYYY-MM-DD)\", \"type\": \"string\"}, \"end_string\": {\"description\": \"End string for the price data (YYYY-MM-DD)\", \"type\": \"string\"}}, \"required\": [\"instrument_type\", \"exchange\"]}, \"required\": null}, {\"name\": \"SEC Filings\", \"description\": \"Returns a list of SEC Filings for the requested company, including filing types, strings, and documents.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"identifier\": {\"description\": \"Publicly traded company\\'s stock symbol or Central Index Key (CIK)\", \"type\": \"string\", \"default\": \"aapl\"}}, \"required\": [\"identifier\"]}, \"required\": null}, {\"name\": \"United States Away from Home Mobility API\", \"description\": \"Retrieve daily data on the percentage change in time spent away from home in the United States, providing insights into the economic impact of the COVID-19 pandemic.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"string\": {\"description\": \"The string for which to retrieve data (format: YYYY-MM-DD)\", \"type\": \"string\"}, \"state\": {\"description\": \"The state for which to retrieve data (optional, default: all states)\", \"type\": \"string\"}}, \"required\": [\"string\"]}, \"required\": null}, {\"name\": \"Calculate Sales Tax\", \"description\": \"Retrieves the sales tax rate applicable to a specific address. This API accepts address inputs to deliver up-to-string, relevant local sales tax rates instantly.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"country\": {\"description\": \"Set to one of the country codes listed in Supported Countries.\", \"type\": \"string\", \"default\": \"US\"}, \"city\": {\"description\": \"City name\", \"type\": \"string\", \"default\": \"Meridian\"}, \"zip\": {\"description\": \"Zip code\", \"type\": \"string\", \"default\": \"83646\"}, \"street\": {\"description\": \"Street address\", \"type\": \"string\", \"default\": \"936 Storey Ave\"}}, \"required\": [\"country\"]}, \"required\": null}]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['tools']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de86da68",
   "metadata": {},
   "source": [
    "## Let's now pre fine-tune the model so it follows our custom GRPO formatting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92eb978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"prompt\"] (num_proc=32):   0%|          | 0/1200 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"prompt\"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1200/1200 [00:01<00:00, 751.69 examples/s] \n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,200 | Num Epochs = 2 | Total steps = 150\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 1 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 983,040 of 355,467,008 (0.28% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 03:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.805200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.814700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.781400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.760500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.751900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.743900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.725900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.751300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.703800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.701800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.724700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.748100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.712900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.778300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.704800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.718600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.713100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.688900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.752700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.708700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.735700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.747700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.692100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.622500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.714000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.7256097173690796, metrics={'train_runtime': 207.6896, 'train_samples_per_second': 11.556, 'train_steps_per_second': 0.722, 'total_flos': 1.0807700146962432e+16, 'train_loss': 0.7256097173690796, 'epoch': 2.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "train_dataset_sft = dataset['train'].select(range(250))\n",
    "eval_dataset_sft = dataset['train'].select(range(250,750))\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset_sft,\n",
    "    eval_dataset=eval_dataset_sft\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"prompt\",\n",
    "        per_device_train_batch_size = 16,\n",
    "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 2, # Set this for 1 full training run.\n",
    "        learning_rate = 2e-5, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 5,\n",
    "        # optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "\n",
    "        report_to = \"tensorboard\", # Use this for WandB etc\n",
    "        max_steps=200\n",
    "\n",
    "    ),\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "057ad746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "search for when is modi born? and who won ipl match<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>web_search\n",
      "<arg_key>searchQuery</arg_key>\n",
      "<arg_value>When is Modi born?</arg_value>\n",
      "<arg_key>arg_key</arg_key>\n",
      "<arg_value>When is Modi born?</arg_value>\n",
      "<arg_key>arg_key</arg_key>\n",
      "<arg_value>Who won IPL match</arg_value>\n",
      "<arg_key>arg_key</arg_key>\n",
      "<arg_value>Who won IPL match</arg_value>\n",
      "</tool_call><|im_end|>\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    [{\"role\":\"user\",\"content\":\"search for when is modi born? and who won ipl match\"}],\n",
    "    tools = list(base_tools.values()),\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    temperature = 0.3,\n",
    "    max_new_tokens = 2048,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df24b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(model) peft.peft_model.PeftModelForCausalLM\n",
    "model.save_pretrained(\"lfm2-sft-tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f13ad960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "search for when is modi born? and who won ipl match<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tool_call>web_search\n",
      "<arg_key>searchQuery</arg_key>\n",
      "<arg_value>When is Modi born?</arg_value>\n",
      "<arg_key>arg_key</arg_key>\n",
      "<arg_value>When is Modi born?</arg_value>\n",
      "<arg_key>arg_key</arg_key>\n",
      "<arg_value>Who won IPL match</arg_value>\n",
      "</tool_call><|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"LiquidAI/LFM2-350M\")\n",
    "sft_peft_model = PeftModel.from_pretrained(base_model, \"lfm2-sft-tool\").to('cuda')\n",
    "text = tokenizer.apply_chat_template(\n",
    "    [{\"role\":\"user\",\"content\":\"search for when is modi born? and who won ipl match\"}],\n",
    "    tools = list(base_tools.values()),\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = sft_peft_model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    temperature = 0.3,\n",
    "    max_new_tokens = 2048,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547af385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"UNSLOTH_VLLM_STANDBY\"] = \"1\"# [NEW] Extra 30% context lengths!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c241f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ng6309/datascience/anand/vllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 10-08 02:03:53 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1008 02:03:53.371000 490200 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "W1008 02:03:53.371000 490200 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "Switching to PyTorch attention since your Xformers is broken.\n",
      "========\n",
      "\n",
      "Requires Flash-Attention version >=2.7.1,<=2.8.2 but got 2.8.3.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.9.9: Fast Lfm2 patching. Transformers: 4.56.2. vLLM: 0.10.2.\n",
      "   \\\\   /|    NVIDIA RTX 6000 Ada Generation. Num GPUs = 1. Max memory: 47.507 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n",
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 8000 # Can increase for longer reasoning traces\n",
    "lora_rank = 32 # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"LiquidAI/LFM2-350M\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False, # False for LoRA 16bit\n",
    "    fast_inference = False, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.9, # Reduce if out of memory\n",
    "\n",
    "    use_exact_model_name = True #for hugginface cache or repo mdoel name\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank*2, # *2 speeds up training\n",
    "    use_gradient_checkpointing = \"unsloth\", # Reduces memory usage\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22aabd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{{- bos_token -}}\\n{%- set system_prompt = \"\" -%}\\n{%- set ns = namespace(system_prompt=\"\") -%}\\n{%- if messages[0][\"role\"] == \"system\" -%}\\n\\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\\n\\t{%- set messages = messages[1:] -%}\\n{%- endif -%}\\n{%- if tools -%}\\n\\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"List of tools: <|tool_list_start|>[\" -%}\\n\\t{%- for tool in tools -%}\\n\\t\\t{%- if tool is not string -%}\\n            {%- set tool = tool | tojson -%}\\n\\t\\t{%- endif -%}\\n\\t\\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\\n        {%- if not loop.last -%}\\n            {%- set ns.system_prompt = ns.system_prompt + \", \" -%}\\n        {%- endif -%}\\n\\t{%- endfor -%}\\n\\t{%- set ns.system_prompt = ns.system_prompt + \"]<|tool_list_end|>\" -%}\\n{%- endif -%}\\n{%- if ns.system_prompt -%}\\n\\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\\n{%- endif -%}\\n{%- for message in messages -%}\\n\\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\\n\\t{%- set content = message[\"content\"] -%}\\n\\t{%- if content is not string -%}\\n\\t\\t{%- set content = content | tojson -%}\\n\\t{%- endif -%}\\n\\t{%- if message[\"role\"] == \"tool\" -%}\\n\\t\\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\\n\\t{%- endif -%}\\n\\t{{- content + \"<|im_end|>\\\\n\" -}}\\n{%- endfor -%}\\n{%- if add_generation_prompt -%}\\n\\t{{- \"<|im_start|>assistant\\\\n\" -}}\\n{%- endif -%}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58ada15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean GLM-style template with line-by-line tool format\n",
    "glm_chat_template = '''{{- bos_token -}}\n",
    "{%- set system_prompt = \"\" -%}\n",
    "{%- set ns = namespace(system_prompt=\"\") -%}\n",
    "{%- if messages[0][\"role\"] == \"system\" -%}\n",
    "\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\n",
    "\t{%- set messages = messages[1:] -%}\n",
    "{%- endif -%}\n",
    "{%- if tools -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\\\\n\" -%}\n",
    "\t{%- for tool in tools -%}\n",
    "\t\t{%- if tool is not string -%}\n",
    "\t\t\t{%- set tool = tool.function | tojson -%}\n",
    "\t\t{%- endif -%}\n",
    "\t\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\n",
    "\t\t{%- if not loop.last -%}\n",
    "\t\t\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n\" -%}\n",
    "\t\t{%- endif -%}\n",
    "\t{%- endfor -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\n",
    "{%- endif -%}\n",
    "{%- if ns.system_prompt -%}\n",
    "\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endif -%}\n",
    "{%- for message in messages -%}\n",
    "\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\n",
    "\t{%- set content = message[\"content\"] -%}\n",
    "\t{%- if content is not string -%}\n",
    "\t\t{%- set content = content | tojson -%}\n",
    "\t{%- endif -%}\n",
    "\t{%- if message[\"role\"] == \"tool\" -%}\n",
    "\t\t{%- set content = \"\\n<|observation|>\\n<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\n",
    "\t{%- endif -%}\n",
    "\t{{- content + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endfor -%}\n",
    "{%- if add_generation_prompt -%}\n",
    "\t{{- \"<|im_start|>assistant\\\\n\" -}}\n",
    "{%- endif -%}'''\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b61407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  \"response\": {\\n    \"type\": \"function\",\\n    \"function\": {\\n      \"name\": \"response\",\\n      \"description\": \"Send a message back to the user.\",\\n      \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n          \"message\": {\\n            \"type\": \"string\",\\n            \"description\": \"The message to send to the user.\"\\n          }\\n        },\\n        \"required\": [\\n          \"message\"\\n        ]\\n      }\\n    }\\n  }\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tools = {\n",
    "  \"web_search\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"web_search\",\n",
    "      \"description\": \"Search the web\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Search query\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"query\"\n",
    "        ]\n",
    "      },\n",
    "      \"return\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "          \"type\": \"object\"\n",
    "        },\n",
    "        \"description\": \"The list of items having url,title,description.\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"think\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"think\",\n",
    "      \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"thought\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A thought to think about.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"thought\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "  \"response\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"response\",\n",
    "      \"description\": \"Send a message back to the user.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"message\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The message to send to the user.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"message\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "142411a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "hiiii<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hiiii\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=list(base_tools.values()), \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d051d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "\n",
      "<|observation|>\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you also search for all candidates for the position of Data Scientist?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>search_database\n",
      "<arg_key>query</arg_key>\n",
      "<arg_value>Data Scientist</arg_value>\n",
      "<arg_key>limit</arg_key>\n",
      "<arg_value>10</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "\n",
      "<|observation|>\n",
      "<|tool_response_start|>[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "I found 2 candidates for the Data Scientist position:\n",
      "1. John Doe (ID: 67890) - Status: Applied\n",
      "2. Jane Smith (ID: 67891) - Status: Interview Completed<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you also search for all candidates for the position of Data Scientist?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>search_database\\n<arg_key>query</arg_key>\\n<arg_value>Data Scientist</arg_value>\\n<arg_key>limit</arg_key>\\n<arg_value>10</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]'},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found 2 candidates for the Data Scientist position:\\n1. John Doe (ID: 67890) - Status: Applied\\n2. Jane Smith (ID: 67891) - Status: Interview Completed\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tools=list(base_tools.values()),\n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99305bb",
   "metadata": {},
   "source": [
    "## Pre fine-tuning for formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46229cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'conversations'],\n",
       "        num_rows: 11300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Team-ACE/ToolACE\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "003f863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tool_call>Get Zip Code Information\n",
      "<arg_key>country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001\")</arg_value>\n",
      "<arg_key>Get Zip Code sdf(country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001</arg_value>\n",
      "</tool_call>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_assistant_response(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    # Match pattern: [FunctionName(arg1=\"val1\", arg2='val2', ...)]\n",
    "    match = re.match(r'\\[(\\w+(?:\\s+\\w+)*)\\((.*)\\)\\]', text)\n",
    "    if not match:\n",
    "        return text  # Not a tool call â†’ return as-is\n",
    "\n",
    "    func_name = match.group(1)\n",
    "    args_str = match.group(2)\n",
    "\n",
    "    # Parse key=value pairs (support both \"...\" and '...')\n",
    "    args = []\n",
    "    for pair in args_str.split(','):\n",
    "        pair = pair.strip()\n",
    "        if '=' in pair:\n",
    "            key, value = pair.split('=', 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip().strip('\"').strip(\"'\")\n",
    "            args.append((key, value))\n",
    "\n",
    "    # Build XML-style output\n",
    "    xml_lines = [f\"<tool_call>{func_name}\"]\n",
    "    for k, v in args:\n",
    "        xml_lines.append(f\"<arg_key>{k}</arg_key>\")\n",
    "        xml_lines.append(f\"<arg_value>{v}</arg_value>\")\n",
    "    xml_lines.append(\"</tool_call>\")\n",
    "    \n",
    "    return \"\\n\".join(xml_lines)\n",
    "\n",
    "inp = '[Get Zip Code Information(country=\"us\", postal_code=\"10001\"),Get Zip Code sdf(country=\"us\", postal_code=\"10001\")]'\n",
    "print(convert_assistant_response(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9bd746d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=32):   0%|          | 0/11300 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11300/11300 [00:00<00:00, 19096.91 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'conversations', 'messages', 'tools'],\n",
       "        num_rows: 11300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_to_messages(example):\n",
    "    _messages = []\n",
    "    tools = example['system'].split(\"Here is a list of functions in JSON format that you can invoke:\")[-1].strip().split(\"Should you decide to return the function call(s)\")[0].replace(\". \\n\",\"\")\n",
    "    for x in example['conversations']:\n",
    "        if x['from'] ==\"assistant\":\n",
    "            _messages.append({\"role\":x['from'],\"content\":convert_assistant_response(x['value'])})\n",
    "        else:\n",
    "            _messages.append({\"role\":x['from'],\"content\":x['value']})\n",
    "\n",
    "    return {\"messages\":_messages,\"tools\":tools}\n",
    "\n",
    "dataset = dataset.map(convert_to_messages,num_proc=32)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b0106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=32):   0%|          | 0/11300 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11300/11300 [00:00<00:00, 19412.45 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'conversations', 'messages', 'tools'],\n",
       "        num_rows: 10782\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_tool(example):\n",
    "    try:\n",
    "            json.loads(example['tools'])\n",
    "    except Exception as e:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "dataset = dataset.filter(filter_tool,num_proc=32)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2789045d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=32):   0%|          | 0/10782 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10782/10782 [00:00<00:00, 14325.15 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'conversations', 'messages', 'tools', 'prompt'],\n",
       "        num_rows: 10782\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def normalize_tool(tool):\n",
    "    # If already in correct format, return as-is\n",
    "    if \"type\" in tool and tool.get(\"type\") == \"function\" and \"function\" in tool:\n",
    "        return tool\n",
    "\n",
    "    # Otherwise, assume it's the old flat format\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": tool[\"name\"],\n",
    "            \"description\": tool.get(\"description\", \"\"),\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": tool.get(\"parameters\", {}).get(\"properties\", {}),\n",
    "                \"required\": tool.get(\"parameters\", {}).get(\"required\", [])\n",
    "                # Note: ignore top-level \"required\": null\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def apply_chat_template(example):\n",
    "    dynamic_tools = json.loads(example['tools'])\n",
    "    normalized_dynamic_tools = [normalize_tool(t) for t in dynamic_tools]\n",
    "    all_tools = list(base_tools.values()) + normalized_dynamic_tools\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        example['messages'],\n",
    "        tools=all_tools,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    return {\"prompt\": prompt}\n",
    "\n",
    "dataset = dataset.map(apply_chat_template,num_proc=32)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6082cc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "{\"name\": \"Quotes by Keywords\", \"description\": \"Returns a list of quotes containing the specified keyword.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"word\": {\"description\": \"The keyword to search for in quotes.\", \"type\": \"string\"}}, \"required\": [\"word\"]}}\n",
      "{\"name\": \"Get Zip Code Information\", \"description\": \"Retrieve information about a specific zip code in the United States.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"country\": {\"description\": \"The country code (default: 'us')\", \"type\": \"string\"}, \"postal_code\": {\"description\": \"The zip code (default: '90210')\", \"type\": \"string\"}}, \"required\": [\"country\", \"postal_code\"]}}\n",
      "{\"name\": \"Weekly Hot 100 Chart\", \"description\": \"Retrieve the Billboard Hot 100 chart for a specific string.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"string\": {\"description\": \"The string for which to retrieve the chart (YYYY-MM-DD)\", \"type\": \"string\"}}, \"required\": [\"string\"]}}\n",
      "{\"name\": \"Get Cars Information\", \"description\": \"This API returns a list of cars information based on the provided parameters.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"model\": {\"description\": \"The model of the vehicle.\", \"type\": \"string\"}, \"make\": {\"description\": \"The manufacturer of the vehicle.\", \"type\": \"string\"}, \"year\": {\"description\": \"The model year of the vehicle.\", \"type\": \"string\"}, \"fuel_type\": {\"description\": \"The type of fuel used.\", \"type\": \"string\"}, \"drive\": {\"description\": \"The drive transmission type.\", \"type\": \"string\"}, \"transmission\": {\"description\": \"The type of transmission.\", \"type\": \"string\"}, \"cylinders\": {\"description\": \"The number of cylinders.\", \"type\": \"float\"}, \"min_city_mpg\": {\"description\": \"Minimum city fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"max_city_mpg\": {\"description\": \"Maximum city fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"min_hwy_mpg\": {\"description\": \"Minimum highway fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"max_hwy_mpg\": {\"description\": \"Maximum highway fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"min_comb_mpg\": {\"description\": \"Minimum combination (city + highway) fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"max_comb_mpg\": {\"description\": \"Maximum combination (city + highway) fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"limit\": {\"description\": \"How many results to return.\", \"type\": \"string\"}}, \"required\": []}}\n",
      "{\"name\": \"Lorem Ipsum Generator\", \"description\": \"Generate a specified number of words of Lorem Ipsum text\", \"parameters\": {\"type\": \"object\", \"properties\": {\"amount\": {\"description\": \"The number of words to generate\", \"type\": \"int\"}}, \"required\": [\"amount\"]}}\n",
      "{\"name\": \"Crawl\", \"description\": \"Perform a Google search and return the HTML source of the results page.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"description\": \"The search query to perform.\", \"type\": \"string\"}}, \"required\": [\"query\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "Could you please find me some quotes about \"inspiration\"?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>Quotes by Keywords\n",
      "<arg_key>word</arg_key>\n",
      "<arg_value>inspiration</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "\n",
      "<|observation|>\n",
      "<|tool_response_start|>[{\"name\": \"Quotes by Keywords\", \"results\": {\"quotes\": [{\"text\": \"The only way to achieve the impossible is to believe it is possible.\", \"author\": \"Charles Kingsleigh\"}, {\"text\": \"Don't watch the clock; do what it does. Keep going.\", \"author\": \"Sam Levenson\"}, {\"text\": \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful.\", \"author\": \"Albert Schweitzer\"}]}}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "Here are some inspiration quotes for you:\n",
      "\n",
      "1. \"The only way to achieve the impossible is to believe it is possible.\" - Charles Kingsleigh\n",
      "2. \"Don't watch the clock; do what it does. Keep going.\" - Sam Levenson\n",
      "3. \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful.\" - Albert Schweitzer\n",
      "\n",
      "Feel free to reflect on these or let me know if you need more quotes or information on another topic!<|im_end|>\n",
      "<|im_start|>user\n",
      "Could you summarize the meaning of the quote by Albert Schweitzer?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The quote by Albert Schweitzer, \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful,\" emphasizes that true success in life comes from finding joy and fulfillment in what you do. Rather than viewing success as a source of happiness, Schweitzer suggests that happiness itself should be the foundation for achieving success. Essentially, when you engage in activities that make you happy and passionate, you're more likely to excel and achieve success in those ventures.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you dig up some juicy details about the zip code 10001? I'm doing a mail-order flamingo business plan, don't ask why.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>Get Zip Code Information\n",
      "<arg_key>country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "\n",
      "<|observation|>\n",
      "<|tool_response_start|>[{\"name\": \"Get Zip Code Information\", \"results\": {\"information\": \"Zip code information for 10001, USA\", \"latitude\": 40.748817, \"longitude\": -73.985428, \"city\": \"New York\", \"state\": \"NY\", \"county\": \"New York\"}}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "Here's the detailed information about the zip code 10001, which will be helpful for your mail-order flamingo business plan:\n",
      "\n",
      "**Zip Code Information for 10001, USA:**\n",
      "- **City:** New York\n",
      "- **State:** NY (New York)\n",
      "- **County:** New York\n",
      "- **Latitude:** 40.748817\n",
      "- **Longitude:** -73.985428\n",
      "\n",
      "This data provides a clear overview of where the zip code is located and its associated geographic details. If you need more assistance or information on any other aspect of your business plan, feel free to ask!<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][1]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca7c4a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"name\": \"newAddress\", \"description\": \"Generates a new Ethereum address that can be used to send or receive funds. Do not lose the password! We can\\'t restore access to an address if you lose it.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"password\": {\"description\": \"The password for the new Ethereum address\", \"type\": \"string\"}}, \"required\": [\"password\"]}, \"required\": null}, {\"name\": \"Market Trends API\", \"description\": \"Get the latest market trends and relevant news for a specified country and language.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"trend_type\": {\"description\": \"Trend type.\", \"type\": \"string\", \"enum\": [\"MARKET_INDEXES\", \"MOST_ACTIVE\", \"GAINERS\", \"LOSERS\", \"CRYPTO\", \"CURRENCIES\", \"CLIMATE_LEADERS\"]}, \"country\": {\"description\": \"The country for which to get trends, specified as a 2-letter country code - see ISO 3166.\", \"type\": \"string\", \"default\": \"us\"}, \"language\": {\"description\": \"The language to use for the results, specified as a 2-letter language code - see ISO 639-1.\", \"type\": \"string\", \"default\": \"en\"}}, \"required\": [\"trend_type\"]}, \"required\": null}, {\"name\": \"Get Futures Prices\", \"description\": \"Retrieve a list of current futures prices for various financial instruments.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"instrument_type\": {\"description\": \"Type of financial instrument (e.g., commodity, currency, index)\", \"type\": \"string\"}, \"exchange\": {\"description\": \"Name of the exchange (e.g., CME, ICE, NYMEX)\", \"type\": \"string\"}, \"start_string\": {\"description\": \"Start string for the price data (YYYY-MM-DD)\", \"type\": \"string\"}, \"end_string\": {\"description\": \"End string for the price data (YYYY-MM-DD)\", \"type\": \"string\"}}, \"required\": [\"instrument_type\", \"exchange\"]}, \"required\": null}, {\"name\": \"SEC Filings\", \"description\": \"Returns a list of SEC Filings for the requested company, including filing types, strings, and documents.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"identifier\": {\"description\": \"Publicly traded company\\'s stock symbol or Central Index Key (CIK)\", \"type\": \"string\", \"default\": \"aapl\"}}, \"required\": [\"identifier\"]}, \"required\": null}, {\"name\": \"United States Away from Home Mobility API\", \"description\": \"Retrieve daily data on the percentage change in time spent away from home in the United States, providing insights into the economic impact of the COVID-19 pandemic.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"string\": {\"description\": \"The string for which to retrieve data (format: YYYY-MM-DD)\", \"type\": \"string\"}, \"state\": {\"description\": \"The state for which to retrieve data (optional, default: all states)\", \"type\": \"string\"}}, \"required\": [\"string\"]}, \"required\": null}, {\"name\": \"Calculate Sales Tax\", \"description\": \"Retrieves the sales tax rate applicable to a specific address. This API accepts address inputs to deliver up-to-string, relevant local sales tax rates instantly.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"country\": {\"description\": \"Set to one of the country codes listed in Supported Countries.\", \"type\": \"string\", \"default\": \"US\"}, \"city\": {\"description\": \"City name\", \"type\": \"string\", \"default\": \"Meridian\"}, \"zip\": {\"description\": \"Zip code\", \"type\": \"string\", \"default\": \"83646\"}, \"street\": {\"description\": \"Street address\", \"type\": \"string\", \"default\": \"936 Storey Ave\"}}, \"required\": [\"country\"]}, \"required\": null}]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['tools']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa9441a",
   "metadata": {},
   "source": [
    "## Chattemplate Explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0d19936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ '<|system|>\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"get_weather\", \"description\": \"Get the weather of a city for a specific date.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"city\": {\"type\": \"string\", \"description\": \"The city to get weather for, in Chinese.\"}, \"date\": {\"type\": \"string\", \"description\": \"The date in YYYY-MM-DD format.\"}}, \"required\": [\"city\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|system|>\n",
      "You are a helpful assistant.' + eos_token }\n",
      "{ '<|user|>' + message['content'] }\n",
      "{ '<|assistant|>' }\n"
     ]
    }
   ],
   "source": [
    "def create_glm_tool_template():\n",
    "    # GLM-4.6 style components\n",
    "    components = {\n",
    "        'think_start': '<think>',\n",
    "        'think_end': '</think>',\n",
    "        'tool_start': '<tool_call>',\n",
    "        'tool_end': '</tool_call>',\n",
    "        'arg_key_start': '<arg_key>',\n",
    "        'arg_key_end': '</arg_key>',\n",
    "        'arg_value_start': '<arg_value>',\n",
    "        'arg_value_end': '</arg_value>',\n",
    "        'observation_start': '<|observation|>',\n",
    "        'system_start': '<|system|>',\n",
    "        'user_start': '<|user|>',\n",
    "        'assistant_start': '<|assistant|>',\n",
    "        'solution_start': '<SOLUTION>',\n",
    "        'solution_end': '</SOLUTION>'\n",
    "    }\n",
    "    \n",
    "    system_prompt_with_tools = f\"\"\"{components['system_start']}\n",
    "# Tools\n",
    "You may call one or more functions to assist with the user query.\n",
    "You are provided with function signatures within <tools></tools> XML tags:\n",
    "<tools>\n",
    "{{\"name\": \"get_weather\", \"description\": \"Get the weather of a city for a specific date.\", \"parameters\": {{\"type\": \"object\", \"properties\": {{\"city\": {{\"type\": \"string\", \"description\": \"The city to get weather for, in Chinese.\"}}, \"date\": {{\"type\": \"string\", \"description\": \"The date in YYYY-MM-DD format.\"}}}}, \"required\": [\"city\"]}}}}\n",
    "</tools>\n",
    "For each function call, output the function name and arguments within the following XML format:\n",
    "{components['tool_start']}{{function-name}}\n",
    "{components['arg_key_start']}{{arg_key}}{components['arg_key_end']}\n",
    "{components['arg_value_start']}{{arg_value}}{components['arg_value_end']}\n",
    "...\n",
    "{components['tool_end']}{components['system_start']}\n",
    "You are a helpful assistant.\"\"\"\n",
    "    \n",
    "    chat_template = f\"\"\"{{% if messages[0]['role'] == 'system' %}}\n",
    "{{ messages[0]['content'] + eos_token }}\n",
    "{{% set loop_messages = messages[1:] %}}\n",
    "{{% else %}}\n",
    "{{ '{system_prompt_with_tools}' + eos_token }}\n",
    "{{% set loop_messages = messages %}}\n",
    "{{% endif %}}\n",
    "{{% for message in loop_messages %}}\n",
    "{{% if message['role'] == 'user' %}}\n",
    "{{ '<|user|>' + message['content'] }}\n",
    "{{% elif message['role'] == 'assistant' %}}\n",
    "{{ '<|assistant|>' + message['content'] + eos_token }}\n",
    "{{% elif message['role'] == 'observation' %}}\n",
    "{{ '<|observation|>' + message['content'] + '<|assistant|>' }}\n",
    "{{% endif %}}\n",
    "{{% endfor %}}\n",
    "{{% if add_generation_prompt %}}{{ '<|assistant|>' }}{{% endif %}}\"\"\"\n",
    "    \n",
    "    return chat_template\n",
    "\n",
    "# Apply the template\n",
    "tokenizer.chat_template = create_glm_tool_template()\n",
    "\n",
    "# Example usage:\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Today is June 26, 2024. Could you please check the weather in Beijing and Shanghai for tomorrow?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"<think>The user wants to check the weather of Beijing and Shanghai tomorrow. I need to call the get_weather function respectively to check Beijing and Shanghai.</think>\\nI will call the get_weather function to check the weather in Beijing and Shanghai.\\n<tool_call>get_weather\\n<arg_key>city</arg_key>\\n<arg_value>Beijing</arg_value>\\n<arg_key>date</arg_key>\\n<arg_value>2024-06-27</arg_value>\\n</tool_call>\\n<tool_call>get_weather\\n<arg_key>city</arg_key>\\n<arg_value>Shanghai</arg_value>\\n<arg_key>date</arg_key>\\n<arg_value>2024-06-27</arg_value>\\n</tool_call>\"},\n",
    "    {\"role\": \"observation\", \"content\": '[{\"city\": \"Beijing\", \"date\": \"2024-06-27\", \"weather\": \"Sunny\", \"temperature\": \"26C\"}, {\"city\": \"Shanghai\", \"date\": \"2024-06-27\", \"weather\": \"Overcast\", \"temperature\": \"29C\"}]'},\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hi\"},\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85758d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "List of tools: <|tool_list_start|>[{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}]<|tool_list_end|><|im_end|>\n",
      "<|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "def create_advanced_glm_compatible_template():\n",
    "    chat_template = \"\"\"{% if messages[0]['role'] == 'system' %}\n",
    "{{ '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>' }}\n",
    "{% set loop_messages = messages[1:] %}\n",
    "{% else %}\n",
    "{{ '<|im_start|>system\\nList of tools: <|tool_list_start|>[{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}]<|tool_list_end|><|im_end|>' }}\n",
    "{% set loop_messages = messages %}\n",
    "{% endif %}\n",
    "{% for message in loop_messages %}\n",
    "{% if message['role'] == 'user' %}\n",
    "{{ '<|im_start|>user\\n' + message['content'] + '<|im_end|>' }}\n",
    "{% elif message['role'] == 'assistant' %}\n",
    "{{ '<|im_start|>assistant\\n' + message['content'] + '<|im_end|>' }}\n",
    "{% elif message['role'] == 'tool' or message['role'] == 'observation' %}\n",
    "{{ '<|im_start|>tool\\n<|tool_response_start|>' + message['content'] + '<|tool_response_end|><|im_end|>' }}\n",
    "{% endif %}\n",
    "{% endfor %}\n",
    "{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n<think>' }}{% endif %}\"\"\"\n",
    "    \n",
    "    return chat_template\n",
    "\n",
    "tokenizer.chat_template = create_advanced_glm_compatible_template()\n",
    "\n",
    "# Example with GLM-style tool calls:\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\\n<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16f6523f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "null\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|system|>\n",
      "You are a helpful assistant.<|im_end|><|user|>hi<|assistant|>\n",
      "\n",
      "==================================================\n",
      "\n",
      "<|system|>\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "null\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|system|>\n",
      "You are a helpful assistant.<|im_end|><|user|>What is the current status of candidate ID 12345?<|assistant|><think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|><|observation|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|assistant|><|assistant|>The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|><|assistant|>\n"
     ]
    }
   ],
   "source": [
    "def create_glm_tool_template(tools_list=None):\n",
    "    import json\n",
    "    tools_json = json.dumps(tools_list, ensure_ascii=False)\n",
    "    \n",
    "    system_prompt_with_tools = f\"\"\"<|system|>\n",
    "# Tools\n",
    "You may call one or more functions to assist with the user query.\n",
    "You are provided with function signatures within <tools></tools> XML tags:\n",
    "<tools>\n",
    "{tools_json}\n",
    "</tools>\n",
    "For each function call, output the function name and arguments within the following XML format:\n",
    "<tool_call>{{function-name}}\n",
    "<arg_key>{{arg_key}}</arg_key>\n",
    "<arg_value>{{arg_value}}</arg_value>\n",
    "...\n",
    "</tool_call><|system|>\n",
    "You are a helpful assistant.\"\"\"\n",
    "    \n",
    "    chat_template = (\n",
    "        \"{% if messages[0]['role'] == 'system' %}\"\n",
    "        \"{{ messages[0]['content'] + eos_token }}\"\n",
    "        \"{% set loop_messages = messages[1:] %}\"\n",
    "        \"{% else %}\"\n",
    "        \"{{ '\" + system_prompt_with_tools.replace('\\n', '\\\\n').replace('\"', '\\\\\"') + \"' + eos_token }}\"\n",
    "        \"{% set loop_messages = messages %}\"\n",
    "        \"{% endif %}\"\n",
    "        \"{% for message in loop_messages %}\"\n",
    "        \"{% if message['role'] == 'user' %}\"\n",
    "        \"{{ '<|user|>' + message['content'] }}\"\n",
    "        \"{% elif message['role'] == 'assistant' %}\"\n",
    "        \"{{ '<|assistant|>' + message['content'] + eos_token }}\"\n",
    "        \"{% elif message['role'] == 'observation' %}\"\n",
    "        \"{{ '<|observation|>' + message['content'] + '<|assistant|>' }}\"\n",
    "        \"{% endif %}\"\n",
    "        \"{% endfor %}\"\n",
    "        \"{% if add_generation_prompt %}{{ '<|assistant|>' }}{% endif %}\"\n",
    "    )\n",
    "    \n",
    "    return chat_template\n",
    "\n",
    "# Example with custom tools\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"search_database\",\n",
    "        \"description\": \"Search the database for specific information\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"The search query\"},\n",
    "                \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create template with custom tools\n",
    "tokenizer.chat_template = create_glm_tool_template()\n",
    "\n",
    "# Test\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hi\"},\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools,\n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test with a full conversation\n",
    "messages_with_tools = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\\n<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"observation\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"}\n",
    "]\n",
    "\n",
    "formatted_full = tokenizer.apply_chat_template(\n",
    "    messages_with_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d93b20b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>[{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}]</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "hi<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "# GLM-style template that preserves the tools parameter functionality\n",
    "glm_chat_template = (\n",
    "    '{{- bos_token -}}\\n'\n",
    "    '{%- set system_prompt = \"\" -%}\\n'\n",
    "    '{%- set ns = namespace(system_prompt=\"\") -%}\\n'\n",
    "    '{%- if messages[0][\"role\"] == \"system\" -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\\n'\n",
    "    '\\t{%- set messages = messages[1:] -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if tools -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>[\" -%}\\n'\n",
    "    '\\t{%- for tool in tools -%}\\n'\n",
    "    '\\t\\t{%- if tool is not string -%}\\n'\n",
    "    '\\t\\t\\t{%- set tool = tool | tojson -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t\\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\\n'\n",
    "    '\\t\\t{%- if not loop.last -%}\\n'\n",
    "    '\\t\\t\\t{%- set ns.system_prompt = ns.system_prompt + \", \" -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t{%- endfor -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + \"]</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if ns.system_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- for message in messages -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\\n'\n",
    "    '\\t{%- set content = message[\"content\"] -%}\\n'\n",
    "    '\\t{%- if content is not string -%}\\n'\n",
    "    '\\t\\t{%- set content = content | tojson -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{%- if message[\"role\"] == \"tool\" -%}\\n'\n",
    "    '\\t\\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{{- content + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endfor -%}\\n'\n",
    "    '{%- if add_generation_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>assistant\\\\n<think>\" -}}\\n'\n",
    "    '{%- endif -%}'\n",
    ")\n",
    "\n",
    "# Apply the new template\n",
    "tokenizer.chat_template = glm_chat_template\n",
    "\n",
    "# Test it\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hi\"},\n",
    "]\n",
    "\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# This should now work with tools parameter\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3aefffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>[{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}, {\"name\": \"search_database\", \"description\": \"Search the database for specific information\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"The search query\"}, \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}}, \"required\": [\"query\"]}}]</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you also search for all candidates for the position of Data Scientist?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>The user wants to search for all candidates for the Data Scientist position. I need to use the search_database tool.</think>\n",
      "<tool_call>search_database\n",
      "<arg_key>query</arg_key>\n",
      "<arg_value>Data Scientist</arg_value>\n",
      "<arg_key>limit</arg_key>\n",
      "<arg_value>10</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "I found 2 candidates for the Data Scientist position:\n",
      "1. John Doe (ID: 67890) - Status: Applied\n",
      "2. Jane Smith (ID: 67891) - Status: Interview Completed<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make sure we have the GLM template applied\n",
    "glm_chat_template = (\n",
    "    '{{- bos_token -}}\\n'\n",
    "    '{%- set system_prompt = \"\" -%}\\n'\n",
    "    '{%- set ns = namespace(system_prompt=\"\") -%}\\n'\n",
    "    '{%- if messages[0][\"role\"] == \"system\" -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\\n'\n",
    "    '\\t{%- set messages = messages[1:] -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if tools -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>[\" -%}\\n'\n",
    "    '\\t{%- for tool in tools -%}\\n'\n",
    "    '\\t\\t{%- if tool is not string -%}\\n'\n",
    "    '\\t\\t\\t{%- set tool = tool | tojson -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t\\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\\n'\n",
    "    '\\t\\t{%- if not loop.last -%}\\n'\n",
    "    '\\t\\t\\t{%- set ns.system_prompt = ns.system_prompt + \", \" -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t{%- endfor -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + \"]</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if ns.system_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- for message in messages -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\\n'\n",
    "    '\\t{%- set content = message[\"content\"] -%}\\n'\n",
    "    '\\t{%- if content is not string -%}\\n'\n",
    "    '\\t\\t{%- set content = content | tojson -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{%- if message[\"role\"] == \"tool\" -%}\\n'\n",
    "    '\\t\\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{{- content + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endfor -%}\\n'\n",
    "    '{%- if add_generation_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>assistant\\\\n<think>\" -}}\\n'\n",
    "    '{%- endif -%}'\n",
    ")\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template\n",
    "\n",
    "# Example with complete conversation flow\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"search_database\",\n",
    "        \"description\": \"Search the database for specific information\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"The search query\"},\n",
    "                \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Complete conversation with user, assistant, and tool messages\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<think>The user wants to check the status of candidate ID 12345. I need to use the get_candidate_status tool.</think>\\n<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you also search for all candidates for the position of Data Scientist?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<think>The user wants to search for all candidates for the Data Scientist position. I need to use the search_database tool.</think>\\n<tool_call>search_database\\n<arg_key>query</arg_key>\\n<arg_value>Data Scientist</arg_value>\\n<arg_key>limit</arg_key>\\n<arg_value>10</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]'},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found 2 candidates for the Data Scientist position:\\n1. John Doe (ID: 67890) - Status: Applied\\n2. Jane Smith (ID: 67891) - Status: Interview Completed\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False  # Don't add generation prompt for complete conversation\n",
    ")\n",
    "\n",
    "print(formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e472f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>[{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}, {\"name\": \"search_database\", \"description\": \"Search the database for specific information\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"The search query\"}, \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}}, \"required\": [\"query\"]}}]</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you also search for all candidates for the position of Data Scientist?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>search_database\n",
      "<arg_key>query</arg_key>\n",
      "<arg_value>Data Scientist</arg_value>\n",
      "<arg_key>limit</arg_key>\n",
      "<arg_value>10</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "I found 2 candidates for the Data Scientist position:\n",
      "1. John Doe (ID: 67890) - Status: Applied\n",
      "2. Jane Smith (ID: 67891) - Status: Interview Completed<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GLM-style template without think tags\n",
    "glm_chat_template = (\n",
    "    '{{- bos_token -}}\\n'\n",
    "    '{%- set system_prompt = \"\" -%}\\n'\n",
    "    '{%- set ns = namespace(system_prompt=\"\") -%}\\n'\n",
    "    '{%- if messages[0][\"role\"] == \"system\" -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\\n'\n",
    "    '\\t{%- set messages = messages[1:] -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if tools -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>[\" -%}\\n'\n",
    "    '\\t{%- for tool in tools -%}\\n'\n",
    "    '\\t\\t{%- if tool is not string -%}\\n'\n",
    "    '\\t\\t\\t{%- set tool = tool | tojson -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t\\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\\n'\n",
    "    '\\t\\t{%- if not loop.last -%}\\n'\n",
    "    '\\t\\t\\t{%- set ns.system_prompt = ns.system_prompt + \", \" -%}\\n'\n",
    "    '\\t\\t{%- endif -%}\\n'\n",
    "    '\\t{%- endfor -%}\\n'\n",
    "    '\\t{%- set ns.system_prompt = ns.system_prompt + \"]</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- if ns.system_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endif -%}\\n'\n",
    "    '{%- for message in messages -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\\n'\n",
    "    '\\t{%- set content = message[\"content\"] -%}\\n'\n",
    "    '\\t{%- if content is not string -%}\\n'\n",
    "    '\\t\\t{%- set content = content | tojson -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{%- if message[\"role\"] == \"tool\" -%}\\n'\n",
    "    '\\t\\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\\n'\n",
    "    '\\t{%- endif -%}\\n'\n",
    "    '\\t{{- content + \"<|im_end|>\\\\n\" -}}\\n'\n",
    "    '{%- endfor -%}\\n'\n",
    "    '{%- if add_generation_prompt -%}\\n'\n",
    "    '\\t{{- \"<|im_start|>assistant\\\\n\" -}}\\n'\n",
    "    '{%- endif -%}'\n",
    ")\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template\n",
    "\n",
    "# Example with complete conversation flow (without think tags)\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"search_database\",\n",
    "        \"description\": \"Search the database for specific information\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"The search query\"},\n",
    "                \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you also search for all candidates for the position of Data Scientist?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>search_database\\n<arg_key>query</arg_key>\\n<arg_value>Data Scientist</arg_value>\\n<arg_key>limit</arg_key>\\n<arg_value>10</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]'},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found 2 candidates for the Data Scientist position:\\n1. John Doe (ID: 67890) - Status: Applied\\n2. Jane Smith (ID: 67891) - Status: Interview Completed\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f072aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "hi<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"get_candidate_status\", \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \"parameters\": {\"type\": \"object\", \"properties\": {\"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}}, \"required\": [\"candidate_id\"]}}\n",
      "{\"name\": \"search_database\", \"description\": \"Search the database for specific information\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"The search query\"}, \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}}, \"required\": [\"query\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you also search for all candidates for the position of Data Scientist?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>search_database\n",
      "<arg_key>query</arg_key>\n",
      "<arg_value>Data Scientist</arg_value>\n",
      "<arg_key>limit</arg_key>\n",
      "<arg_value>10</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|tool_response_start|>[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "I found 2 candidates for the Data Scientist position:\n",
      "1. John Doe (ID: 67890) - Status: Applied\n",
      "2. Jane Smith (ID: 67891) - Status: Interview Completed<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean GLM-style template with line-by-line tool format\n",
    "glm_chat_template = '''{{- bos_token -}}\n",
    "{%- set system_prompt = \"\" -%}\n",
    "{%- set ns = namespace(system_prompt=\"\") -%}\n",
    "{%- if messages[0][\"role\"] == \"system\" -%}\n",
    "\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\n",
    "\t{%- set messages = messages[1:] -%}\n",
    "{%- endif -%}\n",
    "{%- if tools -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\\\\n\" -%}\n",
    "\t{%- for tool in tools -%}\n",
    "\t\t{%- if tool is not string -%}\n",
    "\t\t\t{%- set tool = tool | tojson -%}\n",
    "\t\t{%- endif -%}\n",
    "\t\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\n",
    "\t\t{%- if not loop.last -%}\n",
    "\t\t\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n\" -%}\n",
    "\t\t{%- endif -%}\n",
    "\t{%- endfor -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\n",
    "{%- endif -%}\n",
    "{%- if ns.system_prompt -%}\n",
    "\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endif -%}\n",
    "{%- for message in messages -%}\n",
    "\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\n",
    "\t{%- set content = message[\"content\"] -%}\n",
    "\t{%- if content is not string -%}\n",
    "\t\t{%- set content = content | tojson -%}\n",
    "\t{%- endif -%}\n",
    "\t{%- if message[\"role\"] == \"tool\" -%}\n",
    "\t\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\n",
    "\t{%- endif -%}\n",
    "\t{{- content + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endfor -%}\n",
    "{%- if add_generation_prompt -%}\n",
    "\t{{- \"<|im_start|>assistant\\\\n\" -}}\n",
    "{%- endif -%}'''\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template\n",
    "\n",
    "# Test with tools\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hi\"},\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(formatted)\n",
    "\n",
    "\n",
    "\n",
    "# Example with complete conversation flow (without think tags)\n",
    "custom_tools = [\n",
    "    {\n",
    "        \"name\": \"get_candidate_status\", \n",
    "        \"description\": \"Retrieves the current status of a candidate in the recruitment process\", \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\", \n",
    "            \"properties\": {\n",
    "                \"candidate_id\": {\"type\": \"string\", \"description\": \"Unique identifier for the candidate\"}\n",
    "            }, \n",
    "            \"required\": [\"candidate_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"search_database\",\n",
    "        \"description\": \"Search the database for specific information\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"The search query\"},\n",
    "                \"limit\": {\"type\": \"integer\", \"description\": \"Number of results to return\"}\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you also search for all candidates for the position of Data Scientist?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>search_database\\n<arg_key>query</arg_key>\\n<arg_value>Data Scientist</arg_value>\\n<arg_key>limit</arg_key>\\n<arg_value>10</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]'},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found 2 candidates for the Data Scientist position:\\n1. John Doe (ID: 67890) - Status: Applied\\n2. Jane Smith (ID: 67891) - Status: Interview Completed\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=custom_tools, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

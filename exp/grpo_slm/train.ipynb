{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547af385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "os.environ[\"UNSLOTH_VLLM_STANDBY\"] = \"1\"# [NEW] Extra 30% context lengths!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c241f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ng6309/datascience/anand/vllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 10-14 03:11:01 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1014 03:11:01.445000 1181414 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "W1014 03:11:01.445000 1181414 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "Switching to PyTorch attention since your Xformers is broken.\n",
      "========\n",
      "\n",
      "Requires Flash-Attention version >=2.7.1,<=2.8.2 but got 2.8.3.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.10.1: Fast Lfm2 patching. Transformers: 4.56.2. vLLM: 0.10.2.\n",
      "   \\\\   /|    NVIDIA RTX 6000 Ada Generation. Num GPUs = 1. Max memory: 47.507 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n",
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 8000 # Can increase for longer reasoning traces\n",
    "lora_rank = 32 # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"LiquidAI/LFM2-350M\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False, # False for LoRA 16bit\n",
    "    fast_inference = False, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.9, # Reduce if out of memory\n",
    "\n",
    "    use_exact_model_name = True #for hugginface cache or repo mdoel name\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank*2, # *2 speeds up training\n",
    "    use_gradient_checkpointing = \"unsloth\", # Reduces memory usage\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22aabd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{{- bos_token -}}\\n{%- set system_prompt = \"\" -%}\\n{%- set ns = namespace(system_prompt=\"\") -%}\\n{%- if messages[0][\"role\"] == \"system\" -%}\\n\\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\\n\\t{%- set messages = messages[1:] -%}\\n{%- endif -%}\\n{%- if tools -%}\\n\\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"List of tools: <|tool_list_start|>[\" -%}\\n\\t{%- for tool in tools -%}\\n\\t\\t{%- if tool is not string -%}\\n            {%- set tool = tool | tojson -%}\\n\\t\\t{%- endif -%}\\n\\t\\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\\n        {%- if not loop.last -%}\\n            {%- set ns.system_prompt = ns.system_prompt + \", \" -%}\\n        {%- endif -%}\\n\\t{%- endfor -%}\\n\\t{%- set ns.system_prompt = ns.system_prompt + \"]<|tool_list_end|>\" -%}\\n{%- endif -%}\\n{%- if ns.system_prompt -%}\\n\\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\\n{%- endif -%}\\n{%- for message in messages -%}\\n\\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\\n\\t{%- set content = message[\"content\"] -%}\\n\\t{%- if content is not string -%}\\n\\t\\t{%- set content = content | tojson -%}\\n\\t{%- endif -%}\\n\\t{%- if message[\"role\"] == \"tool\" -%}\\n\\t\\t{%- set content = \"<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\\n\\t{%- endif -%}\\n\\t{{- content + \"<|im_end|>\\\\n\" -}}\\n{%- endfor -%}\\n{%- if add_generation_prompt -%}\\n\\t{{- \"<|im_start|>assistant\\\\n\" -}}\\n{%- endif -%}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ab24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean GLM-style template with line-by-line tool format\n",
    "# glm_chat_template = '''{{- bos_token -}}\n",
    "# {%- set system_prompt = \"\" -%}\n",
    "# {%- set ns = namespace(system_prompt=\"\") -%}\n",
    "# {%- if messages[0][\"role\"] == \"system\" -%}\n",
    "# \t{%- set ns.system_prompt = messages[0][\"content\"] -%}\n",
    "# \t{%- set messages = messages[1:] -%}\n",
    "# {%- endif -%}\n",
    "# {%- if tools -%}\n",
    "# \t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\\\\n\" -%}\n",
    "# \t{%- for tool in tools -%}\n",
    "# \t\t{%- if tool is not string -%}\n",
    "# \t\t\t{%- set tool = tool.function | tojson -%}\n",
    "# \t\t{%- endif -%}\n",
    "# \t\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\n",
    "# \t\t{%- if not loop.last -%}\n",
    "# \t\t\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n\" -%}\n",
    "# \t\t{%- endif -%}\n",
    "# \t{%- endfor -%}\n",
    "# \t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\n",
    "# {%- endif -%}\n",
    "# {%- if ns.system_prompt -%}\n",
    "# \t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\n",
    "# {%- endif -%}\n",
    "# {%- for message in messages -%}\n",
    "# \t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\n",
    "# \t{%- set content = message[\"content\"] -%}\n",
    "# \t{%- if content is not string -%}\n",
    "# \t\t{%- set content = content | tojson -%}\n",
    "# \t{%- endif -%}\n",
    "# \t{%- if message[\"role\"] == \"tool\" -%}\n",
    "# \t{%- if message.get('name') -%}\n",
    "#  \t\t{%- set content = \"<|observation|>\\n<tool_name>\" + message.get('name', 'unknown') + \"</tool_name>\\n<tool_response>\" + content + \"</tool_response>\" -%}\n",
    "# \t{%- else -%}\n",
    "# \t\t{%- set content = \"\\n<|observation|>\\n<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\n",
    "# \t{%- endif -%}\n",
    "# \t{%- endif -%}\n",
    "# \t{{- content + \"<|im_end|>\\\\n\" -}}\n",
    "# {%- endfor -%}\n",
    "# {%- if add_generation_prompt -%}\n",
    "# \t{{- \"<|im_start|>assistant\\\\n\" -}}\n",
    "# {%- endif -%}'''\n",
    "\n",
    "# tokenizer.chat_template = glm_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58ada15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean GLM-style template with line-by-line tool format\n",
    "glm_chat_template = '''{{- bos_token -}}\n",
    "{%- set system_prompt = \"\" -%}\n",
    "{%- set ns = namespace(system_prompt=\"\") -%}\n",
    "{%- if messages[0][\"role\"] == \"system\" -%}\n",
    "\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\n",
    "\t{%- set messages = messages[1:] -%}\n",
    "{%- endif -%}\n",
    "{%- if tools -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\\\\n\" -%}\n",
    "\t{%- for tool in tools -%}\n",
    "\t\t{%- if tool is not string -%}\n",
    "\t\t\t{%- set tool = tool.function | tojson -%}\n",
    "\t\t{%- endif -%}\n",
    "\t\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\n",
    "\t\t{%- if not loop.last -%}\n",
    "\t\t\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n\" -%}\n",
    "\t\t{%- endif -%}\n",
    "\t{%- endfor -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\n",
    "{%- endif -%}\n",
    "{%- if ns.system_prompt -%}\n",
    "\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endif -%}\n",
    "{%- for message in messages -%}\n",
    "\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\n",
    "\t{%- set content = message[\"content\"] -%}\n",
    "\t{%- if content is not string -%}\n",
    "\t\t{%- set content = content | tojson -%}\n",
    "\t{%- endif -%}\n",
    "\t{%- if message[\"role\"] == \"tool\" -%}\n",
    "\t{%- if message.get('name') -%}\n",
    " \t\t{%- set content = \"<|observation|>\\n<tool_name>\" + message.get('name', 'unknown') + \"</tool_name>\\n<tool_response>\" + content + \"</tool_response>\" -%}\n",
    "\t{%- else -%}\n",
    "\t\t{%- set content = \"\\n<|observation|>\\n<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\n",
    "\t{%- endif -%}\n",
    "\t{%- endif -%}\n",
    "\t{{- content + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endfor -%}\n",
    "{%- if add_generation_prompt -%}\n",
    "\t{{- \"<|im_start|>assistant\\\\n\" -}}\n",
    "{%- endif -%}'''\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b61407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  \"response\": {\\n    \"type\": \"function\",\\n    \"function\": {\\n      \"name\": \"response\",\\n      \"description\": \"Send a message back to the user.\",\\n      \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n          \"message\": {\\n            \"type\": \"string\",\\n            \"description\": \"The message to send to the user.\"\\n          }\\n        },\\n        \"required\": [\\n          \"message\"\\n        ]\\n      }\\n    }\\n  }\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tools = {\n",
    "  \"web_search\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"web_search\",\n",
    "      \"description\": \"Search the web\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Search query\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"query\"\n",
    "        ]\n",
    "      },\n",
    "      \"return\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "          \"type\": \"object\"\n",
    "        },\n",
    "        \"description\": \"The list of items having url,title,description.\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"think\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"think\",\n",
    "      \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"thought\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A thought to think about.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"thought\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "  \"response\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"response\",\n",
    "      \"description\": \"Send a message back to the user.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"message\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The message to send to the user.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"message\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf9d044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call>\n"
     ]
    }
   ],
   "source": [
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you also search for all candidates for the position of Data Scientist?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>search_database\\n<arg_key>query</arg_key>\\n<arg_value>Data Scientist</arg_value>\\n<arg_key>limit</arg_key>\\n<arg_value>10</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"name\":\"search_database\",\"content\": '[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]'},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found 2 candidates for the Data Scientist position:\\n1. John Doe (ID: 67890) - Status: Applied\\n2. Jane Smith (ID: 67891) - Status: Interview Completed\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tools=list(base_tools.values()),\n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "sp = re.split(r\"<\\|im_start\\|>system\\s*|\\s*<\\|im_end\\|>\", formatted, maxsplit=2)[1].strip()\n",
    "print(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "142411a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "hiiii<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"hiiii\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tools=list(base_tools.values()), \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d051d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "What is the current status of candidate ID 12345?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>get_candidate_status\n",
      "<arg_key>candidate_id</arg_key>\n",
      "<arg_value>12345</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "\n",
      "<|observation|>\n",
      "<|tool_response_start|>{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}<|tool_response_end|><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The candidate with ID 12345 is currently in the \"Interview Scheduled\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you also search for all candidates for the position of Data Scientist?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>search_database\n",
      "<arg_key>query</arg_key>\n",
      "<arg_value>Data Scientist</arg_value>\n",
      "<arg_key>limit</arg_key>\n",
      "<arg_value>10</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|observation|>\n",
      "<tool_name>search_database</tool_name>\n",
      "<tool_response>[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]</tool_response><|im_end|>\n",
      "<|im_start|>assistant\n",
      "I found 2 candidates for the Data Scientist position:\n",
      "1. John Doe (ID: 67890) - Status: Applied\n",
      "2. Jane Smith (ID: 67891) - Status: Interview Completed<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete conversation with user, assistant, and tool messages (no think tags)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the current status of candidate ID 12345?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>get_candidate_status\\n<arg_key>candidate_id</arg_key>\\n<arg_value>12345</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"content\": '{\"candidate_id\": \"12345\", \"status\": \"Interview Scheduled\", \"position\": \"Clinical Research Associate\", \"date\": \"2023-11-20\"}'},\n",
    "    {\"role\": \"assistant\", \"content\": \"The candidate with ID 12345 is currently in the \\\"Interview Scheduled\\\" stage for the position of Clinical Research Associate, with an interview date set for 2023-11-20.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you also search for all candidates for the position of Data Scientist?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '<tool_call>search_database\\n<arg_key>query</arg_key>\\n<arg_value>Data Scientist</arg_value>\\n<arg_key>limit</arg_key>\\n<arg_value>10</arg_value>\\n</tool_call>'},\n",
    "    {\"role\": \"tool\", \"name\":\"search_database\",\"content\": '[{\"candidate_id\": \"67890\", \"name\": \"John Doe\", \"status\": \"Applied\"}, {\"candidate_id\": \"67891\", \"name\": \"Jane Smith\", \"status\": \"Interview Completed\"}]'},\n",
    "    {\"role\": \"assistant\", \"content\": \"I found 2 candidates for the Data Scientist position:\\n1. John Doe (ID: 67890) - Status: Applied\\n2. Jane Smith (ID: 67891) - Status: Interview Completed\"}\n",
    "]\n",
    "\n",
    "formatted = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tools=list(base_tools.values()),\n",
    "    tokenize=False, \n",
    "    add_generation_prompt=False\n",
    ")\n",
    "\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99305bb",
   "metadata": {},
   "source": [
    "## Pre fine-tuning for formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46229cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'conversations'],\n",
       "        num_rows: 11300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Team-ACE/ToolACE\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "003f863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tool_call>Get Zip Code Information\n",
      "<arg_key>country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001\")</arg_value>\n",
      "<arg_key>Get Zip Code sdf(country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001</arg_value>\n",
      "</tool_call>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_assistant_response(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    # Match pattern: [FunctionName(arg1=\"val1\", arg2='val2', ...)]\n",
    "    match = re.match(r'\\[(\\w+(?:\\s+\\w+)*)\\((.*)\\)\\]', text)\n",
    "    if not match:\n",
    "        return text  # Not a tool call â†’ return as-is\n",
    "\n",
    "    func_name = match.group(1)\n",
    "    args_str = match.group(2)\n",
    "\n",
    "    # Parse key=value pairs (support both \"...\" and '...')\n",
    "    args = []\n",
    "    for pair in args_str.split(','):\n",
    "        pair = pair.strip()\n",
    "        if '=' in pair:\n",
    "            key, value = pair.split('=', 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip().strip('\"').strip(\"'\")\n",
    "            args.append((key, value))\n",
    "\n",
    "    # Build XML-style output\n",
    "    xml_lines = [f\"<tool_call>{func_name}\"]\n",
    "    for k, v in args:\n",
    "        xml_lines.append(f\"<arg_key>{k}</arg_key>\")\n",
    "        xml_lines.append(f\"<arg_value>{v}</arg_value>\")\n",
    "    xml_lines.append(\"</tool_call>\")\n",
    "    \n",
    "    return \"\\n\".join(xml_lines)\n",
    "\n",
    "inp = '[Get Zip Code Information(country=\"us\", postal_code=\"10001\"),Get Zip Code sdf(country=\"us\", postal_code=\"10001\")]'\n",
    "print(convert_assistant_response(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ou3f1felb5m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing fixed function:\n",
      "\n",
      "Input: [Get Zip Code Information(country=\"us\", postal_code=\"10001\")]\n",
      "Output:\n",
      "<tool_call>Get Zip Code Information\n",
      "<arg_key>country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001</arg_value>\n",
      "</tool_call>\n",
      "--------------------------------------------------------------------------------\n",
      "Input: [Get Zip Code Information(country=\"us\", postal_code=\"10001\"),Get Zip Code sdf(country=\"us\", postal_code=\"10001\")]\n",
      "Output:\n",
      "<tool_call>Get Zip Code Information\n",
      "<arg_key>country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001</arg_value>\n",
      "</tool_call>\n",
      "\n",
      "<tool_call>Get Zip Code sdf\n",
      "<arg_key>country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001</arg_value>\n",
      "</tool_call>\n",
      "--------------------------------------------------------------------------------\n",
      "Input: [SEC Filings(identifier=\"AAPL\")]\n",
      "Output:\n",
      "<tool_call>SEC Filings\n",
      "<arg_key>identifier</arg_key>\n",
      "<arg_value>AAPL</arg_value>\n",
      "</tool_call>\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_assistant_response_fixed(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Fixed version that handles multiple function calls properly.\n",
    "    Converts format: [FunctionName(arg1=\"val1\", arg2=\"val2\")]\n",
    "    To: <tool_call>FunctionName\\n<arg_key>arg1</arg_key>\\n<arg_value>val1</arg_value>...\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Check if it looks like a tool call format\n",
    "    if not text.startswith('[') or not text.endswith(']'):\n",
    "        return text  # Not a tool call â†’ return as-is\n",
    "    \n",
    "    # Remove outer brackets\n",
    "    text = text[1:-1].strip()\n",
    "    \n",
    "    # Split multiple function calls by '),FunctionName(' or '),' patterns\n",
    "    # This regex finds function boundaries\n",
    "    function_pattern = r'(\\w+(?:\\s+\\w+)*)\\s*\\((.*?)\\)(?:,|$)'\n",
    "    matches = re.finditer(function_pattern, text)\n",
    "    \n",
    "    results = []\n",
    "    for match in matches:\n",
    "        func_name = match.group(1).strip()\n",
    "        args_str = match.group(2).strip()\n",
    "        \n",
    "        # Parse key=value pairs more carefully\n",
    "        args = []\n",
    "        # Use a more robust regex to handle quoted values with commas inside\n",
    "        arg_pattern = r'(\\w+)\\s*=\\s*([\"\\'])([^\"\\']*)\\2'\n",
    "        for arg_match in re.finditer(arg_pattern, args_str):\n",
    "            key = arg_match.group(1)\n",
    "            value = arg_match.group(3)  # The content between quotes\n",
    "            args.append((key, value))\n",
    "        \n",
    "        # Build XML-style output for this function call\n",
    "        xml_lines = [f\"<tool_call>{func_name}\"]\n",
    "        for k, v in args:\n",
    "            xml_lines.append(f\"<arg_key>{k}</arg_key>\")\n",
    "            xml_lines.append(f\"<arg_value>{v}</arg_value>\")\n",
    "        xml_lines.append(\"</tool_call>\")\n",
    "        \n",
    "        results.append(\"\\n\".join(xml_lines))\n",
    "    \n",
    "    return \"\\n\\n\".join(results) if results else text\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    '[Get Zip Code Information(country=\"us\", postal_code=\"10001\")]',\n",
    "    '[Get Zip Code Information(country=\"us\", postal_code=\"10001\"),Get Zip Code sdf(country=\"us\", postal_code=\"10001\")]',\n",
    "    '[SEC Filings(identifier=\"AAPL\")]',\n",
    "]\n",
    "\n",
    "print(\"Testing fixed function:\\n\")\n",
    "for test in test_cases:\n",
    "    print(f\"Input: {test}\")\n",
    "    print(f\"Output:\\n{convert_assistant_response_fixed(test)}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9bd746d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': \"I'm considering investing and I'd like to know what's happening in the market right now. Could you get me the top market trends in the US?\",\n",
       "  'name': '',\n",
       "  'role': 'user'},\n",
       " {'content': '<tool_call>Market Trends API\\n<arg_key>trend_type</arg_key>\\n<arg_value>MARKET_INDEXES</arg_value>\\n<arg_key>country</arg_key>\\n<arg_value>us</arg_value>\\n</tool_call>',\n",
       "  'name': '',\n",
       "  'role': 'assistant'},\n",
       " {'content': '{\"trends\": [{\"name\": \"S&P 500\", \"description\": \"Standard & Poor\\'s 500 Index is a market-capitalization-weighted index of the 500 largest U.S. publicly traded companies.\", \"data\": {\"current_value\": \"4172.80\", \"percentage_change\": \"+0.68%\"}}, {\"name\": \"DOW J\", \"description\": \"Dow Jones Industrial Average is a price-weighted average of 30 blue-chip stocks that are generally the leaders in their industry.\", \"data\": {\"current_value\": \"34479.60\", \"percentage_change\": \"+0.47%\"}}, {\"name\": \"NASDAQ\", \"description\": \"The NASDAQ Composite is a broad-based capitalization-weighted index of stocks in all three NASDAQ tiers: Global Select, Global Market and Capital Market.\", \"data\": {\"current_value\": \"13691.30\", \"percentage_change\": \"+0.90%\"}}]}',\n",
       "  'name': 'Market Trends API',\n",
       "  'role': 'tool'},\n",
       " {'content': \"Here are the top Market Trends in the US right now:\\n\\n1. **S&P 500**: The Standard & Poor's 500 Index is a market-capitalization-weighted index of the 500 largest U.S. publicly traded companies. Its current value is 4172.80 with a percentage change of +0.68%.\\n\\n2. **DOW J**: The Dow Jones Industrial Average is a price-weighted average of 30 blue-chip stocks that are generally the leaders in their industry. Its current value is 34479.60 with a percentage change of +0.47%.\\n\\n3. **NASDAQ**: The NASDAQ Composite is a broad-based capitalization-weighted index of stocks in all three NASDAQ tiers: Global Select, Global Market and Capital Market. Its current value is 13691.30 with a percentage change of +0.90%.\\n\\nThis information can help you make informed decisions about your investment plans.\",\n",
       "  'name': '',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Could you explain what SEC filings are and how they might be useful for an investor like me?',\n",
       "  'name': '',\n",
       "  'role': 'user'},\n",
       " {'content': \"Sure, SEC filings refer to official documents that are submitted by publicly traded companies to the U.S. Securities and Exchange Commission (SEC). These documents provide valuable information about a company's financial performance, its management team, ownership, key business operations, market competition, and future prospects. They are typically comprehensive and contain detailed information that a company is legally required to disclose to the public.\\n\\nInvestors like you can use these filings to better understand a company's true financial health and operations. Information you might glean from SEC filings includes:\\n\\n1. **Financial Statements**: Balance sheets, income statements, and cash flow statements can help you analyze the financial health and profitability of a company.\\n\\n2. **Management Discussion and Analysis (MD&A)**: This section offers management's perspective on the company's performance, including explanations of financial results, significant changes, market risk exposures, and future operations and strategy.\\n\\n3. **Risk Factors**: In the filing, companies are required to disclose potential risks of investing in their company. Insight into the risks the company is facing can help you make a more informed decision about investing.\\n\\n4. **Major Shareholders**: Companies must disclose the list of major shareholders. High ownership of shares by insiders could indicate confidence in the business, while large institutional ownership could suggest stability.\\n\\n5. **Director and Executive Compensation**: Information on executive remuneration packages can indicate how well the companyâ€™s interests are aligned with its executive team.\\n\\nSEC filings are a fundamental part of investment research and due diligence. They can provide deep insights into a company that may not be immediately obvious from simply looking at its earnings or share price. It's essential for investors to understand how to read and interpret these filings to make informed investment decisions.\",\n",
       "  'name': '',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'So, a couple of years ago, I invested in a tech startup without doing any proper research. It seemed like a hot trend at the time, but the company went belly up within a year. I ended up losing a good chunk of money. What are your thoughts on that?',\n",
       "  'name': '',\n",
       "  'role': 'user'},\n",
       " {'content': \"As an assistant, I'm here to provide advice and guide you in your financial decisions. Here are my thoughts:\\n\\nInvesting in startups or any company without conducting proper research carries high risk. Although some startups have very high growth potentials and can provide excellent returns, many also fail within a few years of operation. This is especially the case in the tech industry where competition is stiff and technology changes rapidly.\\n\\nThat being said, your past experience with the tech startup is an important lesson in the necessity of conducting thorough due diligence before investing. Here are some steps you might take before future investments:\\n\\n1. **Understand the Business**: Make sure you understand the company's business model, its products or services, the market it operates in and its competition.\\n\\n2. **Financial Analysis**: Review financial statements, revenue, profitability, growth rates, debt levels, and cash flow. \\n\\n3. **Management Review**: It's important to assess the quality of the management team and their plans for the company.\\n\\n4. **Use of Tools**: Utilize tools like the SEC Filings tool to retrieve important documents to get detailed information about a company's operations, management and financials.\\n\\n5. **Risk vs Reward**: Analyze the investment's potential returns in light of the potential risk. High-risk investments should have the potential for higher returns.\\n\\nRemember, all investments carry a degree of risk. As such, it can be beneficial to diversify investments to spread risk and not put all of your money into one company or sector. It may also be helpful to seek advice from financial advisors or use trusted financial services to ensure informed decisions.\\n\\nGoing forward, employing these strategies could help reduce risk and maximize potential returns on your investments.\",\n",
       "  'name': '',\n",
       "  'role': 'assistant'},\n",
       " {'content': \"Could you provide me with the SEC filings for Apple? Also, Iâ€™m curious about how COVID-19 has affected people's mobility away from home in the US.\",\n",
       "  'name': '',\n",
       "  'role': 'user'},\n",
       " {'content': '<tool_call>SEC Filings\\n<arg_key>identifier</arg_key>\\n<arg_value>AAPL</arg_value>\\n</tool_call>\\n\\n<tool_call>United States Away from Home Mobility API\\n<arg_key>string</arg_key>\\n<arg_value>2025-05-17</arg_value>\\n</tool_call>',\n",
       "  'name': '',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def prepare_tool(text):\n",
    "    import json\n",
    "    data = json.loads(text)\n",
    "    tool_results = []\n",
    "    for x in data:\n",
    "        tool_results.append({\"role\":\"tool\",\"name\":x['name'],\"content\":json.dumps((x['results']))})\n",
    "    return tool_results\n",
    "\n",
    "def convert_to_messages(example):\n",
    "    _messages = []\n",
    "    tools = example['system'].split(\"Here is a list of functions in JSON format that you can invoke:\")[-1].strip().split(\"Should you decide to return the function call(s)\")[0].replace(\". \\n\",\"\")\n",
    "    for x in example['conversations']:\n",
    "        if x['from'] ==\"assistant\":\n",
    "            _messages.append({\"role\":x['from'],\"name\":\"\",\"content\":convert_assistant_response_fixed(x['value'])})\n",
    "        elif x['from']=='tool':\n",
    "            _messages.extend(prepare_tool(x['value']))\n",
    "        else:\n",
    "            _messages.append({\"role\":x['from'],\"name\":\"\",\"content\":x['value']})\n",
    "\n",
    "    return {\"messages\":_messages,\"tools\":tools}\n",
    "\n",
    "dataset = dataset.map(convert_to_messages,num_proc=32)\n",
    "dataset['train'][0]['messages']\n",
    "# convert_to_messages(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b0106b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'conversations', 'messages', 'tools'],\n",
       "        num_rows: 10782\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_tool(example):\n",
    "    try:\n",
    "            json.loads(example['tools'])\n",
    "    except Exception as e:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "dataset = dataset.filter(filter_tool,num_proc=32)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2789045d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'conversations', 'messages', 'tools', 'prompt'],\n",
       "        num_rows: 10782\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def normalize_tool(tool):\n",
    "    # If already in correct format, return as-is\n",
    "    if \"type\" in tool and tool.get(\"type\") == \"function\" and \"function\" in tool:\n",
    "        return tool\n",
    "\n",
    "    # Otherwise, assume it's the old flat format\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": tool[\"name\"],\n",
    "            \"description\": tool.get(\"description\", \"\"),\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": tool.get(\"parameters\", {}).get(\"properties\", {}),\n",
    "                \"required\": tool.get(\"parameters\", {}).get(\"required\", [])\n",
    "                # Note: ignore top-level \"required\": null\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "def apply_chat_template(example):\n",
    "    dynamic_tools = json.loads(example['tools'])\n",
    "    normalized_dynamic_tools = [normalize_tool(t) for t in dynamic_tools]\n",
    "    all_tools = list(base_tools.values()) + normalized_dynamic_tools\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        example['messages'],\n",
    "        tools=all_tools,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    return {\"prompt\": prompt}\n",
    "\n",
    "dataset = dataset.map(apply_chat_template,num_proc=32)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71072861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Could you please find me some quotes about \"inspiration\"?', 'name': '', 'role': 'user'}, {'content': '<tool_call>Quotes by Keywords\\n<arg_key>word</arg_key>\\n<arg_value>inspiration</arg_value>\\n</tool_call>', 'name': '', 'role': 'assistant'}, {'content': '{\"quotes\": [{\"text\": \"The only way to achieve the impossible is to believe it is possible.\", \"author\": \"Charles Kingsleigh\"}, {\"text\": \"Don\\'t watch the clock; do what it does. Keep going.\", \"author\": \"Sam Levenson\"}, {\"text\": \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful.\", \"author\": \"Albert Schweitzer\"}]}', 'name': 'Quotes by Keywords', 'role': 'tool'}, {'content': 'Here are some inspiration quotes for you:\\n\\n1. \"The only way to achieve the impossible is to believe it is possible.\" - Charles Kingsleigh\\n2. \"Don\\'t watch the clock; do what it does. Keep going.\" - Sam Levenson\\n3. \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful.\" - Albert Schweitzer\\n\\nFeel free to reflect on these or let me know if you need more quotes or information on another topic!', 'name': '', 'role': 'assistant'}, {'content': 'Could you summarize the meaning of the quote by Albert Schweitzer?', 'name': '', 'role': 'user'}, {'content': 'The quote by Albert Schweitzer, \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful,\" emphasizes that true success in life comes from finding joy and fulfillment in what you do. Rather than viewing success as a source of happiness, Schweitzer suggests that happiness itself should be the foundation for achieving success. Essentially, when you engage in activities that make you happy and passionate, you\\'re more likely to excel and achieve success in those ventures.', 'name': '', 'role': 'assistant'}, {'content': \"Can you dig up some juicy details about the zip code 10001? I'm doing a mail-order flamingo business plan, don't ask why.\", 'name': '', 'role': 'user'}, {'content': '<tool_call>Get Zip Code Information\\n<arg_key>country</arg_key>\\n<arg_value>us</arg_value>\\n<arg_key>postal_code</arg_key>\\n<arg_value>10001</arg_value>\\n</tool_call>', 'name': '', 'role': 'assistant'}, {'content': '{\"information\": \"Zip code information for 10001, USA\", \"latitude\": 40.748817, \"longitude\": -73.985428, \"city\": \"New York\", \"state\": \"NY\", \"county\": \"New York\"}', 'name': 'Get Zip Code Information', 'role': 'tool'}, {'content': \"Here's the detailed information about the zip code 10001, which will be helpful for your mail-order flamingo business plan:\\n\\n**Zip Code Information for 10001, USA:**\\n- **City:** New York\\n- **State:** NY (New York)\\n- **County:** New York\\n- **Latitude:** 40.748817\\n- **Longitude:** -73.985428\\n\\nThis data provides a clear overview of where the zip code is located and its associated geographic details. If you need more assistance or information on any other aspect of your business plan, feel free to ask!\", 'name': '', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][1]['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6082cc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "{\"name\": \"Quotes by Keywords\", \"description\": \"Returns a list of quotes containing the specified keyword.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"word\": {\"description\": \"The keyword to search for in quotes.\", \"type\": \"string\"}}, \"required\": [\"word\"]}}\n",
      "{\"name\": \"Get Zip Code Information\", \"description\": \"Retrieve information about a specific zip code in the United States.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"country\": {\"description\": \"The country code (default: 'us')\", \"type\": \"string\"}, \"postal_code\": {\"description\": \"The zip code (default: '90210')\", \"type\": \"string\"}}, \"required\": [\"country\", \"postal_code\"]}}\n",
      "{\"name\": \"Weekly Hot 100 Chart\", \"description\": \"Retrieve the Billboard Hot 100 chart for a specific string.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"string\": {\"description\": \"The string for which to retrieve the chart (YYYY-MM-DD)\", \"type\": \"string\"}}, \"required\": [\"string\"]}}\n",
      "{\"name\": \"Get Cars Information\", \"description\": \"This API returns a list of cars information based on the provided parameters.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"model\": {\"description\": \"The model of the vehicle.\", \"type\": \"string\"}, \"make\": {\"description\": \"The manufacturer of the vehicle.\", \"type\": \"string\"}, \"year\": {\"description\": \"The model year of the vehicle.\", \"type\": \"string\"}, \"fuel_type\": {\"description\": \"The type of fuel used.\", \"type\": \"string\"}, \"drive\": {\"description\": \"The drive transmission type.\", \"type\": \"string\"}, \"transmission\": {\"description\": \"The type of transmission.\", \"type\": \"string\"}, \"cylinders\": {\"description\": \"The number of cylinders.\", \"type\": \"float\"}, \"min_city_mpg\": {\"description\": \"Minimum city fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"max_city_mpg\": {\"description\": \"Maximum city fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"min_hwy_mpg\": {\"description\": \"Minimum highway fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"max_hwy_mpg\": {\"description\": \"Maximum highway fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"min_comb_mpg\": {\"description\": \"Minimum combination (city + highway) fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"max_comb_mpg\": {\"description\": \"Maximum combination (city + highway) fuel efficiency in miles per gallon.\", \"type\": \"float\"}, \"limit\": {\"description\": \"How many results to return.\", \"type\": \"string\"}}, \"required\": []}}\n",
      "{\"name\": \"Lorem Ipsum Generator\", \"description\": \"Generate a specified number of words of Lorem Ipsum text\", \"parameters\": {\"type\": \"object\", \"properties\": {\"amount\": {\"description\": \"The number of words to generate\", \"type\": \"int\"}}, \"required\": [\"amount\"]}}\n",
      "{\"name\": \"Crawl\", \"description\": \"Perform a Google search and return the HTML source of the results page.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"description\": \"The search query to perform.\", \"type\": \"string\"}}, \"required\": [\"query\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "Could you please find me some quotes about \"inspiration\"?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>Quotes by Keywords\n",
      "<arg_key>word</arg_key>\n",
      "<arg_value>inspiration</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|observation|>\n",
      "<tool_name>Quotes by Keywords</tool_name>\n",
      "<tool_response>{\"quotes\": [{\"text\": \"The only way to achieve the impossible is to believe it is possible.\", \"author\": \"Charles Kingsleigh\"}, {\"text\": \"Don't watch the clock; do what it does. Keep going.\", \"author\": \"Sam Levenson\"}, {\"text\": \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful.\", \"author\": \"Albert Schweitzer\"}]}</tool_response><|im_end|>\n",
      "<|im_start|>assistant\n",
      "Here are some inspiration quotes for you:\n",
      "\n",
      "1. \"The only way to achieve the impossible is to believe it is possible.\" - Charles Kingsleigh\n",
      "2. \"Don't watch the clock; do what it does. Keep going.\" - Sam Levenson\n",
      "3. \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful.\" - Albert Schweitzer\n",
      "\n",
      "Feel free to reflect on these or let me know if you need more quotes or information on another topic!<|im_end|>\n",
      "<|im_start|>user\n",
      "Could you summarize the meaning of the quote by Albert Schweitzer?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The quote by Albert Schweitzer, \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful,\" emphasizes that true success in life comes from finding joy and fulfillment in what you do. Rather than viewing success as a source of happiness, Schweitzer suggests that happiness itself should be the foundation for achieving success. Essentially, when you engage in activities that make you happy and passionate, you're more likely to excel and achieve success in those ventures.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you dig up some juicy details about the zip code 10001? I'm doing a mail-order flamingo business plan, don't ask why.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>Get Zip Code Information\n",
      "<arg_key>country</arg_key>\n",
      "<arg_value>us</arg_value>\n",
      "<arg_key>postal_code</arg_key>\n",
      "<arg_value>10001</arg_value>\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<|observation|>\n",
      "<tool_name>Get Zip Code Information</tool_name>\n",
      "<tool_response>{\"information\": \"Zip code information for 10001, USA\", \"latitude\": 40.748817, \"longitude\": -73.985428, \"city\": \"New York\", \"state\": \"NY\", \"county\": \"New York\"}</tool_response><|im_end|>\n",
      "<|im_start|>assistant\n",
      "Here's the detailed information about the zip code 10001, which will be helpful for your mail-order flamingo business plan:\n",
      "\n",
      "**Zip Code Information for 10001, USA:**\n",
      "- **City:** New York\n",
      "- **State:** NY (New York)\n",
      "- **County:** New York\n",
      "- **Latitude:** 40.748817\n",
      "- **Longitude:** -73.985428\n",
      "\n",
      "This data provides a clear overview of where the zip code is located and its associated geographic details. If you need more assistance or information on any other aspect of your business plan, feel free to ask!<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][1]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca7c4a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"name\": \"newAddress\", \"description\": \"Generates a new Ethereum address that can be used to send or receive funds. Do not lose the password! We can\\'t restore access to an address if you lose it.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"password\": {\"description\": \"The password for the new Ethereum address\", \"type\": \"string\"}}, \"required\": [\"password\"]}, \"required\": null}, {\"name\": \"Market Trends API\", \"description\": \"Get the latest market trends and relevant news for a specified country and language.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"trend_type\": {\"description\": \"Trend type.\", \"type\": \"string\", \"enum\": [\"MARKET_INDEXES\", \"MOST_ACTIVE\", \"GAINERS\", \"LOSERS\", \"CRYPTO\", \"CURRENCIES\", \"CLIMATE_LEADERS\"]}, \"country\": {\"description\": \"The country for which to get trends, specified as a 2-letter country code - see ISO 3166.\", \"type\": \"string\", \"default\": \"us\"}, \"language\": {\"description\": \"The language to use for the results, specified as a 2-letter language code - see ISO 639-1.\", \"type\": \"string\", \"default\": \"en\"}}, \"required\": [\"trend_type\"]}, \"required\": null}, {\"name\": \"Get Futures Prices\", \"description\": \"Retrieve a list of current futures prices for various financial instruments.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"instrument_type\": {\"description\": \"Type of financial instrument (e.g., commodity, currency, index)\", \"type\": \"string\"}, \"exchange\": {\"description\": \"Name of the exchange (e.g., CME, ICE, NYMEX)\", \"type\": \"string\"}, \"start_string\": {\"description\": \"Start string for the price data (YYYY-MM-DD)\", \"type\": \"string\"}, \"end_string\": {\"description\": \"End string for the price data (YYYY-MM-DD)\", \"type\": \"string\"}}, \"required\": [\"instrument_type\", \"exchange\"]}, \"required\": null}, {\"name\": \"SEC Filings\", \"description\": \"Returns a list of SEC Filings for the requested company, including filing types, strings, and documents.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"identifier\": {\"description\": \"Publicly traded company\\'s stock symbol or Central Index Key (CIK)\", \"type\": \"string\", \"default\": \"aapl\"}}, \"required\": [\"identifier\"]}, \"required\": null}, {\"name\": \"United States Away from Home Mobility API\", \"description\": \"Retrieve daily data on the percentage change in time spent away from home in the United States, providing insights into the economic impact of the COVID-19 pandemic.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"string\": {\"description\": \"The string for which to retrieve data (format: YYYY-MM-DD)\", \"type\": \"string\"}, \"state\": {\"description\": \"The state for which to retrieve data (optional, default: all states)\", \"type\": \"string\"}}, \"required\": [\"string\"]}, \"required\": null}, {\"name\": \"Calculate Sales Tax\", \"description\": \"Retrieves the sales tax rate applicable to a specific address. This API accepts address inputs to deliver up-to-string, relevant local sales tax rates instantly.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"country\": {\"description\": \"Set to one of the country codes listed in Supported Countries.\", \"type\": \"string\", \"default\": \"US\"}, \"city\": {\"description\": \"City name\", \"type\": \"string\", \"default\": \"Meridian\"}, \"zip\": {\"description\": \"Zip code\", \"type\": \"string\", \"default\": \"83646\"}, \"street\": {\"description\": \"Street address\", \"type\": \"string\", \"default\": \"936 Storey Ave\"}}, \"required\": [\"country\"]}, \"required\": null}]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['tools']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de86da68",
   "metadata": {},
   "source": [
    "## Let's now pre fine-tune the model so it follows our custom GRPO formatting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f92eb978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 250 | Num Epochs = 7 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 983,040 of 355,467,008 (0.28% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 03:21, Epoch 6/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.179100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.895900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.700500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.573700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.242900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.967300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.496900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.573400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>2.361800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.270300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>2.199600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.977900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>2.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.902200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "train_dataset_sft = dataset['train'].select(range(250))\n",
    "eval_dataset_sft = dataset['train'].select(range(250,750))\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset_sft,\n",
    "    eval_dataset=eval_dataset_sft,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"prompt\",\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 4,# Increase to 4 for smoother training\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 2, # Set this for 1 full training run.\n",
    "        learning_rate = 2e-5, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 5,\n",
    "        # optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "\n",
    "        report_to = \"tensorboard\", # Use this for WandB etc\n",
    "        max_steps=100,\n",
    "\n",
    "        # eval_strategy=\"steps\",  # evaluate during training\n",
    "        # eval_steps=10,                # evaluate every 10 steps\n",
    "        # eval_delay=10,                # wait until step 10 to start evaluating\n",
    "        # save_strategy=\"steps\",        # optional: save model at eval points\n",
    "        # save_steps=10,                # optional: save every eval\n",
    "\n",
    "    ),\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "#type(model) peft.peft_model.PeftModelForCausalLM\n",
    "model.save_pretrained(\"lfm2-sft-tool\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "057ad746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "search for when is modi born? and who won ipl match<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tool_call>{web_search}\n",
      "<query>When is Modi born? Who won IPL match?</query>\n",
      "</tool_call><|im_end|>\n"
     ]
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    [{\"role\":\"user\",\"content\":\"search for when is modi born? and who won ipl match\"}],\n",
    "    tools = list(base_tools.values()),\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    temperature = 0.3,\n",
    "    max_new_tokens = 2048,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f13ad960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "search for when is modi born? and who won ipl match<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>{web_search}\n",
      "<query>When is Modi born? Who won IPL match?</query>\n",
      "</tool_call><|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"LiquidAI/LFM2-350M\")\n",
    "sft_peft_model = PeftModel.from_pretrained(base_model, \"lfm2-sft-tool\").to('cuda')\n",
    "text = tokenizer.apply_chat_template(\n",
    "    [{\"role\":\"user\",\"content\":\"search for when is modi born? and who won ipl match\"}],\n",
    "    tools = list(base_tools.values()),\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "_ = sft_peft_model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    temperature = 0.3,\n",
    "    max_new_tokens = 2048,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "113ad361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1028"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32db087",
   "metadata": {},
   "source": [
    "## GRPO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a636933f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt'],\n",
       "        num_rows: 10782\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_system_prompt_based_messages(example):\n",
    "    sp = re.split(r\"<\\|im_start\\|>system\\s*|\\s*<\\|im_end\\|>\", example['prompt'], maxsplit=2)[1].strip()\n",
    "    return {\"prompt\":[{\"role\":\"system\",'content':sp},*example['messages']]}\n",
    "\n",
    "grpo_dataset = dataset.map(get_system_prompt_based_messages,num_proc=32, remove_columns=[\"messages\",\"system\", 'conversations', 'tools'])\n",
    "grpo_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "22521fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (32/32 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10782/10782 [00:01<00:00, 10417.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# def get_answer(exp): return {\"answer\":\"22\",\"samples\":[12]}\n",
    "# grpo_dataset = grpo_dataset.map(get_answer,num_proc=32)\n",
    "# grpo_dataset\n",
    "grpo_dataset.save_to_disk('tool-ace-dataset-grpo',num_proc=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c8061dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'answer', 'samples'],\n",
       "        num_rows: 10782\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpo_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a44abcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.10.1: Fast Lfm2 patching. Transformers: 4.56.2. vLLM: 0.10.2.\n",
      "   \\\\   /|    NVIDIA RTX 6000 Ada Generation. Num GPUs = 1. Max memory: 47.507 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt'],\n",
      "        num_rows: 10782\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import unsloth\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Load model using Unsloth's FastLanguageModel\n",
    "max_seq_length = 8000\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"lfm2-sft-tool\",  # Load the SFT fine-tuned model directly\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False,\n",
    "    fast_inference = False,\n",
    "    gpu_memory_utilization = 0.9,\n",
    ")\n",
    "\n",
    "dataset = load_dataset('tool-ace-dataset-grpo',num_proc=32)\n",
    "print(dataset)\n",
    "\n",
    "glm_chat_template = '''{{- bos_token -}}\n",
    "{%- set system_prompt = \"\" -%}\n",
    "{%- set ns = namespace(system_prompt=\"\") -%}\n",
    "{%- if messages[0][\"role\"] == \"system\" -%}\n",
    "\t{%- set ns.system_prompt = messages[0][\"content\"] -%}\n",
    "\t{%- set messages = messages[1:] -%}\n",
    "{%- endif -%}\n",
    "{%- if tools -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + (\"\\\\n\" if ns.system_prompt else \"\") + \"# Tools\\\\nYou may call one or more functions to assist with the user query.\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\\\\n\" -%}\n",
    "\t{%- for tool in tools -%}\n",
    "\t\t{%- if tool is not string -%}\n",
    "\t\t\t{%- set tool = tool.function | tojson -%}\n",
    "\t\t{%- endif -%}\n",
    "\t\t{%- set ns.system_prompt = ns.system_prompt + tool -%}\n",
    "\t\t{%- if not loop.last -%}\n",
    "\t\t\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n\" -%}\n",
    "\t\t{%- endif -%}\n",
    "\t{%- endfor -%}\n",
    "\t{%- set ns.system_prompt = ns.system_prompt + \"\\\\n</tools>\\\\nFor each function call, output the function name and arguments within the following XML format:\\\\n<tool_call>{function-name}\\\\n<arg_key>{arg_key}</arg_key>\\\\n<arg_value>{arg_value}</arg_value>\\\\n...\\\\n</tool_call>\" -%}\n",
    "{%- endif -%}\n",
    "{%- if ns.system_prompt -%}\n",
    "\t{{- \"<|im_start|>system\\\\n\" + ns.system_prompt + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endif -%}\n",
    "{%- for message in messages -%}\n",
    "\t{{- \"<|im_start|>\" + message[\"role\"] + \"\\\\n\" -}}\n",
    "\t{%- set content = message[\"content\"] -%}\n",
    "\t{%- if content is not string -%}\n",
    "\t\t{%- set content = content | tojson -%}\n",
    "\t{%- endif -%}\n",
    "\t{%- if message[\"role\"] == \"tool\" -%}\n",
    "\t{%- if message.get('name') -%}\n",
    " \t\t{%- set content = \"<|observation|>\\n<tool_name>\" + message.get('name', 'unknown') + \"</tool_name>\\n<tool_response>\" + content + \"</tool_response>\" -%}\n",
    "\t{%- else -%}\n",
    "\t\t{%- set content = \"\\n<|observation|>\\n<|tool_response_start|>\" + content + \"<|tool_response_end|>\" -%}\n",
    "\t{%- endif -%}\n",
    "\t{%- endif -%}\n",
    "\t{{- content + \"<|im_end|>\\\\n\" -}}\n",
    "{%- endfor -%}\n",
    "{%- if add_generation_prompt -%}\n",
    "\t{{- \"<|im_start|>assistant\\\\n\" -}}\n",
    "{%- endif -%}'''\n",
    "base_tools = {\n",
    "  \"web_search\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"web_search\",\n",
    "      \"description\": \"Search the web\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Search query\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"query\"\n",
    "        ]\n",
    "      },\n",
    "      \"return\": {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "          \"type\": \"object\"\n",
    "        },\n",
    "        \"description\": \"The list of items having url,title,description.\"\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"think\": {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"think\",\n",
    "      \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"thought\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A thought to think about.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"thought\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    [{\"role\":\"user\",\"content\":\"search for when is modi born? and who won ipl match\"}],\n",
    "    tools = list(base_tools.values()),\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33e83403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|><|startoftext|><|im_start|>system\n",
      "# Tools\n",
      "You may call one or more functions to assist with the user query.\n",
      "You are provided with function signatures within <tools></tools> XML tags:\n",
      "<tools>\n",
      "{\"name\": \"web_search\", \"description\": \"Search the web\", \"parameters\": {\"type\": \"object\", \"properties\": {\"query\": {\"type\": \"string\", \"description\": \"Search query\"}}, \"required\": [\"query\"]}, \"return\": {\"type\": \"array\", \"items\": {\"type\": \"object\"}, \"description\": \"The list of items having url,title,description.\"}}\n",
      "{\"name\": \"think\", \"description\": \"Use the tool to think about something. It will not obtain new information or change the database, but just append the thought to the log. Use it when complex reasoning or some cache memory is needed.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"thought\": {\"type\": \"string\", \"description\": \"A thought to think about.\"}}, \"required\": [\"thought\"]}}\n",
      "</tools>\n",
      "For each function call, output the function name and arguments within the following XML format:\n",
      "<tool_call>{function-name}\n",
      "<arg_key>{arg_key}</arg_key>\n",
      "<arg_value>{arg_value}</arg_value>\n",
      "...\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "search for when is modi born? and who won ipl match<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>{web_search}\n",
      "<query>When is Modi born? Who won IPL match?</query>\n",
      "</tool_call><|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "_ = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    temperature = 0.3,\n",
    "    max_new_tokens = 2048,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e25831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def check_answer(prompts, completions, **kwargs):\n",
    "    scores = []\n",
    "    for comp in completions:\n",
    "        # Extract the content string (assuming structure like [{\"content\": \"...\"}])\n",
    "        content = comp[0]['content']\n",
    "        length = len(content)\n",
    "        \n",
    "        # Define max desirable length\n",
    "        max_good_length = 500\n",
    "        \n",
    "        if length <= max_good_length:\n",
    "            # Shorter = better â†’ higher score\n",
    "            # Normalize: score = 1 - (length / max_good_length)\n",
    "            # So 0 chars â†’ 1.0, 500 chars â†’ 0.0\n",
    "            score = 1.0 - (length / max_good_length)\n",
    "        else:\n",
    "            # Penalize long responses: give low or zero reward\n",
    "            score = 0.0\n",
    "        \n",
    "        # Optional: keep 2 decimal places\n",
    "        score = round(score, 2)\n",
    "        scores.append(score)\n",
    "    \n",
    "    print(\"Scores:\", scores)\n",
    "    return scores\n",
    "\n",
    "\n",
    "maximum_length = 6000\n",
    "max_prompt_length = maximum_length + 1 # + 1 just in case!\n",
    "max_completion_length = max_seq_length - max_prompt_length\n",
    "\n",
    "from unsloth import vLLMSamplingParams\n",
    "vllm_sampling_params = vLLMSamplingParams(\n",
    "    min_p = 0.1,\n",
    "    top_p = 1.0,\n",
    "    top_k = -1,\n",
    "    seed = 3407,\n",
    "    stop = [tokenizer.eos_token],\n",
    "    include_stop_str_in_output = True,\n",
    ")\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "# First create the config without vllm_sampling_params\n",
    "training_args = GRPOConfig(\n",
    "    temperature = 1.0,\n",
    "    learning_rate = 5e-6,\n",
    "    weight_decay = 0.01,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    # optim = \"adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
    "    num_generations = 4, # Decrease if out of memory\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_completion_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 100,\n",
    "    save_steps = 100,\n",
    "    report_to = \"tensorboard\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs\",\n",
    "    torch_compile = False,  # Disable torch.compile to avoid dimension mismatch errors\n",
    "\n",
    "    # For optional training + evaluation\n",
    "    # fp16_full_eval = True,\n",
    "    # per_device_eval_batch_size = 4,\n",
    "    # eval_accumulation_steps = 1,\n",
    "    # eval_strategy = \"steps\",\n",
    "    # eval_steps = 1,\n",
    ")\n",
    "\n",
    "# Add vllm_sampling_params after creation to avoid JSON serialization issues\n",
    "training_args.vllm_sampling_params = vllm_sampling_params\n",
    "\n",
    "# Patch the to_dict method to exclude vllm_sampling_params from serialization\n",
    "original_to_dict = training_args.to_dict\n",
    "def patched_to_dict():\n",
    "    d = original_to_dict()\n",
    "    # Remove vllm_sampling_params from the dict to avoid JSON serialization error\n",
    "    d.pop('vllm_sampling_params', None)\n",
    "    return d\n",
    "training_args.to_dict = patched_to_dict\n",
    "\n",
    "# For optional training + evaluation\n",
    "train_dataset_for_grpo = dataset['train'].select(range(250,300))\n",
    "# new_dataset = dataset.train_test_split(test_size = 0.01)\n",
    "\n",
    "tokenizer.chat_template = glm_chat_template\n",
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        # match_format_exactly,\n",
    "        # match_format_approximately,\n",
    "        check_answer,\n",
    "        # check_numbers,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset_for_grpo,\n",
    "\n",
    "    # For optional training + evaluation\n",
    "    # train_dataset = new_dataset[\"train\"],\n",
    "    # eval_dataset = new_dataset[\"test\"],\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# from transformers import TextStreamer\n",
    "# _ = sft_peft_model.generate(\n",
    "#     **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "#     temperature = 0.3,\n",
    "#     max_new_tokens = 2048,\n",
    "#     streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

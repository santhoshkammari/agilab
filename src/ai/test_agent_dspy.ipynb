{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demo_simple_loop():\n",
    "    print(\"DEMO 1: Simple Agent Loop\")\n",
    "\n",
    "    lm = LM(api_base=\"http://192.168.170.76:8000\")\n",
    "    tools = [get_weather, search]\n",
    "    history = [{\"role\": \"user\", \"content\": \"What is the weather in London and Paris? /no_think\"}]\n",
    "    async for chunk in  agent(lm=lm,history=history,tools=tools, max_iterations=5):\n",
    "        print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936d27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LM(api_base=\"http://192.168.170.76:8000\")\n",
    "sig = Signature(\"query,context -> answer\")\n",
    "agent = Agent(\n",
    "    #optional\n",
    "    # lm=lm\n",
    ")\n",
    "evaluate = Evaluate()\n",
    "\n",
    "agent.stream()\n",
    "agent(lm=lm)\n",
    "\n",
    "\n",
    "## different prompts test\n",
    "## different models test\n",
    "## everything plug and playable.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "What a prompt does to llm? \n",
    "what is a perfect prompt?\n",
    "how we know the prompt is turing complete?\n",
    "inducing the behaviour into LLM prompt via dataset correlation.\n",
    "\n",
    "auto synth ? \n",
    "using internet for high quality synth dataset creation?\n",
    "\n",
    "\n",
    "generate multiple QA pairs which will be used for creting features. \n",
    "scaled thinking \n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
